[{"content":"Hi üëã #üè¢ DevOps @Claranet France\n","date":null,"permalink":"/","section":"/home","summary":"Hi üëã #üè¢ DevOps @Claranet France","title":"/home"},{"content":" R√©alis√© dans le cadre de mon ann√©e de Bachelor, le Hackaton √† pour but de proposer une solution informatique en une semaine. Un jury juge ensuite la solution la plus convaincante et d√©signe les vainqueurs.\nL\u0026rsquo;ensemble du projet que j\u0026rsquo;ai r√©alis√© est disponible en open-source\nsur GitLab\nEtant encore √©tudiant et loin d\u0026rsquo;√™tre un sp√©cialiste K8S, le projet pr√©sent√© sur cette page comporte forc√©ment de grosses impr√©cisions et d\u0026rsquo;√©normes failles de s√©curit√©. Si par hasard un DevOps confirm√© tombe sur ces lignes, n\u0026rsquo;h√©sites pas √† me contacter via la section commentaire ou via email, j\u0026rsquo;aurais quelques questions √† te poser üòâ Introduction #Lors de ce hackathon, mon √©quipe √† choisi pour sujet Solution Libre. Il s\u0026rsquo;agissait de :\nd√©velopper le frontend d\u0026rsquo;une application √† destination de formateurs et de leurs √©l√®ves d√©velopper l\u0026rsquo;architecture qui permettra in fine d\u0026rsquo;h√©berger l\u0026rsquo;application, son backend et sa base de donn√©es proposer une CI/CD permettant de mettre en place une livraison et une int√©gration continue de l\u0026rsquo;applicatif et son infrastructure Le back-end √©tant fourni par l\u0026rsquo;√©cole, mon travail ici se limitait √† son int√©gration ainsi qu\u0026rsquo;a celle du front-end.\nContexte et travail d\u0026rsquo;√©quipe #L\u0026rsquo;ensemble des √©tudiants de l\u0026rsquo;√©cole sont r√©unis en √©quipe de 10, tout niveaux et sp√©cialit√©s confondues. Toute la difficult√© √©tant de coordonner l\u0026rsquo;ensemble de l\u0026rsquo;√©quipe afin de livrer un produit fonctionnel.\nLimites et difficult√©s #Malheureusement, l\u0026rsquo;√©quipe dont j\u0026rsquo;ai fais partie n\u0026rsquo;as pas s√ª d√©livrer un front-end dans les temps impartis. Cela dit, de mon c√¥t√© j\u0026rsquo;ai pu architecturer l\u0026rsquo;ensemble de l\u0026rsquo;infrastructure ainsi que la pipeline CI/CD et obtenir un POC fonctionnel. Il ne me manquais plus qu\u0026rsquo;un front-end afin d\u0026rsquo;obtenir le r√©sultat demand√©, dommage üò•!\nCependant, j\u0026rsquo;ai pu tester le fonctionnement du back-end sur l\u0026rsquo;architecture ainsi d√©ploy√©e. C\u0026rsquo;est d\u0026rsquo;ailleurs l\u0026rsquo;objet de cet article : pr√©senter ma solution sur la partie DevOps üòé.\nSch√©ma d\u0026rsquo;architecture #J\u0026rsquo;ai r√©alis√© un petit brouillon de l\u0026rsquo;architecture que j\u0026rsquo;ai souhait√© mettre en place sur le cloud Azure :\nOn √† donc:\nUn cluster Kubernetes manag√© sur le cloud Azure (AKS) 3 namepsaces : un pour le front, un pour le back et le dernier pour le monitoring et la gestion des logs Lors de la r√©alisation, j\u0026rsquo;ai regroup√© tout mes pods K8S au sein du m√™me namespace par manque de temps lors du d√©veloppement de la partie Terraform. La partie monitoring est aussi inachev√©e et ne figure pas sur le repo. Cela dit, il n\u0026rsquo;est pas exclu que je m\u0026rsquo;y penche dans le cadre d\u0026rsquo;un article de blog dans un futur proche. En l\u0026rsquo;√©tat, l\u0026rsquo;architecture disponible sur le lien GitLab donn√©e en pr√©ambule permet uniquement de requ√™ter l\u0026rsquo;API du backend. De plus, comme indiqu√© sur le sch√©ma la base de donn√©e utilis√©e est h√©berg√©e dans un pod. J\u0026rsquo;aurais pr√©f√©r√© mettre en place une base de donn√©e manag√©e mais n\u0026rsquo;√©tant pas encore tr√®s √† l\u0026rsquo;aise avec Kubernetes sur Azure, j\u0026rsquo;ai pr√©f√©r√© aller au plus simple. Le but de cet article reste pour moi l\u0026rsquo;occasion de garder une sorte de documentation sur le projet r√©alis√©. A ne pas utiliser en production donc üòâ.\nInfrastructure As Code #Contexte #L\u0026rsquo;enjeu √©tant de provisioner tout cela as code, j\u0026rsquo;ai d√©ploy√© cette architecture avec Terraform. Le repo contenant l\u0026rsquo;infrastructure est construit comme ceci:\n‚îî‚îÄ‚îÄ terraform ‚îú‚îÄ‚îÄ aks.tf ‚îú‚îÄ‚îÄ environment ‚îÇ¬†‚îî‚îÄ‚îÄ dev ‚îÇ¬†‚îî‚îÄ‚îÄ variables.tfvars ‚îú‚îÄ‚îÄ kubernetes.tf ‚îú‚îÄ‚îÄ main.tf ‚îú‚îÄ‚îÄ modules ‚îÇ¬†‚îî‚îÄ‚îÄ kubernetes ‚îÇ¬†‚îú‚îÄ‚îÄ main.tf ‚îÇ¬†‚îú‚îÄ‚îÄ outputs.tf ‚îÇ¬†‚îî‚îÄ‚îÄ variables.tf ‚îú‚îÄ‚îÄ outputs.tf ‚îú‚îÄ‚îÄ rg.tf ‚îú‚îÄ‚îÄ variables.tf ‚îî‚îÄ‚îÄ vpc.tf Cette architecture est d√®s le d√©part con√ßue pour √™tre en mesure de d√©ployer des environments ISO dev/pprd/prod. Cela permet au d√©veloppeur d\u0026rsquo;√™tre en mesure (en th√©orie) de tester son code en amont sur des architectures identiques avant de d√©ployer l\u0026rsquo;applicatif en production.\nBackend et providers #Dans le fichier main.tf, en d√©but de code on retrouve la d√©claration du backend, ainsi que les providers requis:\nterraform { backend \u0026#34;azurerm\u0026#34; { resource_group_name = \u0026#34;backend-terraform-rg\u0026#34; storage_account_name = \u0026#34;backendhackatonsdv\u0026#34; container_name = \u0026#34;terraform-state\u0026#34; key = \u0026#34;terraform.tfstate\u0026#34; } required_providers { azurerm = { source = \u0026#34;hashicorp/azurerm\u0026#34; version = \u0026#34;3.63.0\u0026#34; } kubernetes = { source = \u0026#34;hashicorp/kubernetes\u0026#34; version = \u0026#34;2.21.1\u0026#34; } } } provider \u0026#34;azurerm\u0026#34; { features {} skip_provider_registration = true } provider \u0026#34;kubernetes\u0026#34; { host = module.aks.host client_certificate = base64decode(module.aks.client_certificate) client_key = base64decode(module.aks.client_key) cluster_ca_certificate = base64decode(module.aks.cluster_ca_certificate) } Le backend, permettant de stocker le fichier tfstate consiste en un compte de stockage Azure h√©bergeant ce m√™me fichier. Dans le cas de ce lab, j\u0026rsquo;ai utilis√© un compte de stockage pr√©alablement existant sur mon compte Azure.\nJ\u0026rsquo;utilise les providers azure_rm et kubernetes permettant de respectivement :\nint√©ragir avec mon compte Azure int√©ragir avec le cluster Kubernetes d√©ploy√© J\u0026rsquo;utilise un compte Azure Students fourni par l\u0026rsquo;√©cole pour ce lab. Terraform refusais syst√©matiquement d\u0026rsquo;apply mon infrastructure en raison d\u0026rsquo;erreurs de droits. L\u0026rsquo;option skip_provider_registration = true m\u0026rsquo;as permis de d√©bloquer la situation. Le provider kubernetes n√©cessite une configuration permettant de se connecter au cluster afin d\u0026rsquo;y d√©ployer les ressources. Ici, je fournis les valeurs dynamiquement √† partir du module aks que je decris plus loin dans l\u0026rsquo;article.\nTerraform et modules #Pour une meilleure lisibilit√©, je pr√©f√®re s√©parer chaque ressources d√©ploy√©es en un fichier distinct. Cela √©vite de se retrouver avec un gros fichier de plusieurs centaines de lignes devenant vite illisible. Terraform permet ensuite d\u0026rsquo;organiser son code en modules. Un module est un ensemble de fichiers Terraform stock√©s dans un dossier. Cela permet d\u0026rsquo;√©viter les r√©p√©titions dans le code et la m√©thode de fonctionnement peut √™tre comparable √† une fonction dans un programme informatique. Ici j\u0026rsquo;ai donc :\naks.tf -\u0026gt; Cr√©e un cluster Kubernetes manag√© via le module Azure/aks/azurerm kubernetes.tf -\u0026gt; Int√©ragit avec le cluster Kubernetes. Ce fichier appelle un module que j\u0026rsquo;ai d√©velopp√© et stock√© dans le r√©pertoire modules rg.tf -\u0026gt; Le groupe de ressource Azure contenant l\u0026rsquo;ensemble des instances vpc.tf -\u0026gt; La configuration r√©seau de l\u0026rsquo;infrastructure Pour finir, dans le fichier variables.tf, je d√©clare les variables qui seront utilis√©es pour d√©ployer l\u0026rsquo;infrastructure. Ces variables sont fournies par le fichier variables.tfvars, qui diff√®re en fonction de l\u0026rsquo;environement de production choisi. Ainsi, au plan ou apply il suffira de rajouter le flag -var-file=environment/dev/variables.tfvars afin de d√©finir l\u0026rsquo;environment choisi. Dans ce lab, il s\u0026rsquo;agit de l\u0026rsquo;environment de dev.\nCI/CD #Containerisation #Pour √™tre en mesure de d√©ployer l\u0026rsquo;infrastructure sur Kubernetes, il m\u0026rsquo;a fallu au pr√©alable containairiser le back-end dans une image Docker pr√™te √† √™tre stock√© sur un registre d\u0026rsquo;images (ici, j\u0026rsquo;utilise celui de GitLab). La m√©thode aurais √©t√© similaire pour le front-end. J\u0026rsquo;ai donc √©cris un Dockerfile :\n# Base Golang Image FROM golang:latest # Setup working directory WORKDIR /usr/src/osf-core # Copy source code to COPY . /usr/src/osf-core # Install Git and NodeJS RUN curl -sL https://deb.nodesource.com/setup_16.x | bash - RUN apt-get install -y nodejs npm # Install NPM dependencies RUN npm install -g @marp-team/marp-core \\ \u0026amp;\u0026amp; npm install -g markdown-it-include \\ \u0026amp;\u0026amp; npm install -g markdown-it-container \\ \u0026amp;\u0026amp; npm install -g markdown-it-attrs # Install Go Library \u0026amp; Swagger RUN cd /usr/src/osf-core \u0026amp;\u0026amp; go get golang.org/x/text/transform \\ \u0026amp;\u0026amp; go get golang.org/x/text/unicode/norm \\ \u0026amp;\u0026amp; go install github.com/swaggo/swag/cmd/swag@v1.8.12 # Init Swagger RUN cd /usr/src/osf-core \u0026amp;\u0026amp; swag init --parseDependency --parseInternal # Export ports EXPOSE 8000/tcp EXPOSE 443/tcp EXPOSE 80/tcp # Launch the API CMD [\u0026#34;go\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;/usr/src/osf-core/main.go\u0026#34;] J\u0026rsquo;ai tent√© d\u0026rsquo;utiliser les fichiers packages.json et go.sum/go.mod afin d\u0026rsquo;installer les d√©pendances directement depuis ces fichiers, mais la g√©n√©ration de mon image plantait. De plus, j\u0026rsquo;ai du forcer la version de swagger en 1.8.12 car un probl√®me de compatibilit√© m\u0026rsquo;emp√™chais de g√©n√©rer la documentation Swagger.\nCe Dockerfile est utilis√© dans la CI afin de g√©n√©rer dynamiquement l\u0026rsquo;image destin√© √† √™tre pouss√©e dans le cluster K8S.\nCI applicative #La CI applicative est tr√®s basique pour ce lab mais il y a quelques sp√©cificit√©s. J\u0026rsquo;utilise une image docker in docker, car pour builder l\u0026rsquo;image applicative il est n√©cessaire d\u0026rsquo;executer des commandes docker dans docker (plus d\u0026rsquo;infos ici). Pour fonctionner correctement, le build d\u0026rsquo;une image Docker par le runner n√©cessite d\u0026rsquo;ajouter ces lignes en d√©but de CI :\nimage: docker:20.10.16 services: - docker:20.10.16-dind variables: DOCKER_TLS_CERTDIR: \u0026#34;/certs\u0026#34; Sans cela, docker serais incapable d\u0026rsquo;acc√©der √† Internet √† l\u0026rsquo;int√©rieur du container.\nLa CI consiste en 3 stages :\ntest deploy trigger_deploy_to_terraform 2 variables sont √† renseigner manuellement : ENV et TAG:\nENV: value: \u0026#34;dev\u0026#34; description: \u0026#34;On wich env the image should be deployed\u0026#34; TAG: value: \u0026#34;latest\u0026#34; description: \u0026#34;Version of the image\u0026#34; Ces variables sont utilis√©es par la suite pour d√©finir sur quel environment d√©ployer l\u0026rsquo;image, et permet √† Terraform de r√©cup√©rer le chemin vers l\u0026rsquo;image √† pousser sur le cluster. Le script qui va cr√©er l\u0026rsquo;image est tr√®s simple :\ndeploy: stage: deploy script: - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_TOKEN $DOCKER_REGISTRY_URL - docker build -t registry.gitlab.com/sdv-open-course-factory/ocf-core/${ENV}-backend:${TAG} . - docker push registry.gitlab.com/sdv-open-course-factory/ocf-core/${ENV}-backend:${TAG} Le nom et le chemin de l\u0026rsquo;image sera renseign√© automatiquement en fonction des donn√©es entr√©es par le dev.\nPour finir, le dernier stage d√©clenche la CI situ√©es sur le repo Terraform, en poussant la variable TAG permettant √† Terraform de pousser la bonne image du backend sur le cluster Kubernetes:\nNew job to trigger the other project\u0026#39;s CI trigger_deploy_to_terraform: image: curlimages/curl stage: trigger_deploy_to_terraform script: - curl -X POST --fail -F token=$CI_TRIGGER_TOKEN -F \u0026#34;ref=main\u0026#34; -F \u0026#34;variables[TAG]=$TAG\u0026#34; https://gitlab.com/api/v4/projects/47370418/trigger/pipeline needs: - deploy Je n\u0026rsquo;ai pas encore variabilis√© l\u0026rsquo;environement √† ce niveau. Pour le moment, ma CI est uniquement en mesure de d√©ployer sur dev. Encore une fois, question de priorit√©s niveau timing. Je cherchais surtout √† avoir quelque chose de fonctionnel au plus vite. Ainsi, seul la variable TAG est envoy√©e √† Terraform, permettant de retrouver l\u0026rsquo;image. CI infrastructure #La CI d\u0026rsquo;infrastructure peut soit √™tre d√©clench√©e par le job trigger de la CI applicative, soit manuellement. On retrouve les stages classiques :\nvalidate plan apply destroy J\u0026rsquo;utilise ici l\u0026rsquo;image hashicorp/terraform:latest, m\u0026rsquo;√©vitant d\u0026rsquo;installer Terraform √† chaque d√©ploiement sur le runner.\nAu niveau des variables :\nvariables: TF_ROOT: ${CI_PROJECT_DIR}/terraform/ TF_ENVIRONMENT: \u0026#34;dev\u0026#34; # D√©finissez l\u0026#39;environnement souhait√© ici (par exemple, dev, preprod, prod) TF_DESTROY: description: Destroy Terraform resources value: \u0026#34;false\u0026#34; Comme dit pr√©c√©demment, l\u0026rsquo;environement et cod√© en dur sur dev dans mon lab La variable TF_DESTROY me permet de d√©truire l\u0026rsquo;infrastructure via la CI. Le stage destroy ne s\u0026rsquo;execute seulement ci la valeur est chang√©e pour true:\nterraform_destroy: stage: destroy script: terraform destroy -auto-approve -var-file=environment/${TF_ENVIRONMENT}/variables.tfvars -var=\u0026#34;img_tag=${TAG}\u0026#34; rules: - if: $TF_DESTROY == \u0026#34;true\u0026#34; when: always La partie plan contient un simple script bash qui va tester l\u0026rsquo;existence de la variable TAG r√©cup√©r√©e depuis la CI applicative :\nif [ -n \u0026#34;$TAG\u0026#34; ]; then terraform plan -var-file=environment/${TF_ENVIRONMENT}/variables.tfvars -var \u0026#34;img_tag=${TAG}\u0026#34; else echo \u0026#34;Nothing to plan\u0026#34; fi J\u0026rsquo;utilise le flag -var-file=environment/${TF_ENVIRONMENT}/variables.tfvars afin de d√©terminer dynamiquement sur quel environenment d√©ployer. Puis le flag -var \u0026quot;img_tag=${TAG} pour d√©terminer l\u0026rsquo;image Docker √† utiliser sur le m√™me principe.\nLe flag -var \u0026quot;img_tag=${TAG} permet de d√©finir la variable Terraform contenue dans le variables.tf √† la racine ainsi que dans le module Kubernetes:\nvariable \u0026#34;img_tag\u0026#34; { description = \u0026#34;Image tag\u0026#34; type = string } L\u0026rsquo;adresse permettant de pointer vers l\u0026rsquo;image est ensuite reconstruite comme ceci lors de la cr√©ation du d√©ploiement Kubernetes:\nspec { container { image = \u0026#34;registry.gitlab.com/sdv-open-course-factory/ocf-core/${var.env}-backend:${var.img_tag}\u0026#34; name = \u0026#34;ocf-core-backend\u0026#34; port { container_port = 80 } port { container_port = 443 } port { container_port = 8000 } Conclusion #J\u0026rsquo;ai eu au final √† peu pr√®s 4 jours pour r√©aliser toute cette architecture. C\u0026rsquo;est assez court, mais le POC est fonctionnel et permet d\u0026rsquo;acc√©der √† la doc swagger du backend et de manipuler l\u0026rsquo;API. Dans l\u0026rsquo;id√©e, pour vraiment d√©ployer ce lab en production il faudrais:\nBien s√ªr y int√©grer un front-end Retravailler la CI pour int√©grer l\u0026rsquo;image du front-end Int√©grer toute la partie monitoring et gestion des logs, c\u0026rsquo;est super important Utiliser une BDD manag√©e Azure au lieu d\u0026rsquo;une image PostegrSQL dans le cluster S√©parer chaque services sur des namespaces diff√©rents Niveau s√©curit√©, placer le loadbalancer sur un subnet s√©par√©. Mettre en place un bastion sur un VPC diff√©rent afin d\u0026rsquo;√™tre en mesure de requ√™ter l\u0026rsquo;API K8S via kubectl. Ici, ‚ö†Ô∏è l\u0026rsquo;API est expos√©e au web ‚ö†Ô∏è Je pense r√©-utiliser mon architecture pour tenter de r√©aliser le front-end. J\u0026rsquo;en profiterais pour consolider le tout par rapport √† la liste ci-dessus. Cela fais aussi quelque temps que je suis int√©ress√© par les technologies de dev orient√© front-end (React) et n\u0026rsquo;ayant pas ou tr√®s peu d\u0026rsquo;exp√©rience en JavaScript, ce serais l\u0026rsquo;occasion. Affaire √† suivre donc\u0026hellip;\n","date":"3 juillet 2023","permalink":"/projets/hackaton_sdv/","section":"Projets","summary":"R√©alis√© dans le cadre de mon ann√©e de Bachelor, le Hackaton √† pour but de proposer une solution informatique en une semaine.","title":"Hackaton Sup De Vinci 2023"},{"content":" Cette page rassemble l\u0026rsquo;ensemble de mes projets scolaires et personnels r√©alis√©s en classe ou sur mon temps libre ","date":null,"permalink":"/projets/","section":"Projets","summary":" Cette page rassemble l\u0026rsquo;ensemble de mes projets scolaires et personnels r√©alis√©s en classe ou sur mon temps libre ","title":"Projets"},{"content":"","date":null,"permalink":"/categories/aws/","section":"Categories","summary":"","title":"Aws"},{"content":"","date":null,"permalink":"/tags/awscli/","section":"Tags","summary":"","title":"Awscli"},{"content":" C\u0026rsquo;est ici que je publie mes articles quand le temps me le permet. üìå Articles r√©cents #","date":null,"permalink":"/blog/","section":"Blog","summary":"C\u0026rsquo;est ici que je publie mes articles quand le temps me le permet.","title":"Blog"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/tags/cloud/","section":"Tags","summary":"","title":"Cloud"},{"content":"","date":null,"permalink":"/tags/cloudformation/","section":"Tags","summary":"","title":"Cloudformation"},{"content":"","date":null,"permalink":"/tags/ec2/","section":"Tags","summary":"","title":"Ec2"},{"content":"","date":null,"permalink":"/tags/gaming/","section":"Tags","summary":"","title":"Gaming"},{"content":"Introduction #Le cloud-gaming se d√©mocratise de plus en plus notamment par le biais d\u0026rsquo;acteurs tel que OVH avec son offre Shadow, ou encore NVDIA avec GeForce Now. Je me suis toujours demand√© par quel proc√©d√© il serais possible de cr√©er mon propre serveur cloud d√©di√© au jeu, et surtout si c\u0026rsquo;√©tait viable. Apr√®s quelques recherches, j\u0026rsquo;ai d√©couvert quelques pistes assez int√©ressantes, notament du c√¥t√© d\u0026rsquo;AWS qui propose des instances de calcul avec GPU plut√¥t abordables : les instances G4.\nAttention √† la facture si tu oublies d\u0026rsquo;√©teindre ou de supprimer ton instance apr√®s avoir d√©roul√© l\u0026rsquo;article! Cet article te permettra de monter ta propre VM GPU, tout en te faisant d√©couvrir aws cli et CloudFormation, l\u0026rsquo;outil d\u0026rsquo;IAC propos√© par AWS.\nLes types d\u0026rsquo;instances G4 #AWS propose deux architectures, l\u0026rsquo;une est bas√©e sur les puces GPU NVIDIA T4 (g4dn), l\u0026rsquo;autre sur des puces AMD Radeon Pro V520 (g4ad). Ci-dessous un tableau comparatif du rapport prix/performances des diff√©rentes instances :\nInstance Type 3DMark Score On-demand Price (us-east-1, USD, 02/23) Price-performance (3DMark points / $) g4dn.xlarge 4300 $0.71 6056 g4dn.2xlarge 4800 $1.12 4286 g4dn.4xlarge 6000 $1.94 3093 g4ad.xlarge 5100 $0.56 9107 g4ad.2xlarge 6600 $0.91 7253 g4ad.4xlarge 7600 $1.60 4750 g5.xlarge 6800 $1.19 5714 g5.2xlarge 10200 $1.58 6456 g5.4xlarge 13000 $2.36 5508 Source : https://github.com/aws-samples/cloud-gaming-on-ec2-instances\nPour cet article, je me base sur une instance AMD g4ad.xlarge, largement suffisante pour mes besoins.\nPr√©requis # Un compte AWS awscli d\u0026rsquo;install√© et de configur√© (voir la doc AWS) Assez de quota sur ton compte AWS pour provisionner des instances GPU G4 (j\u0026rsquo;explique plus bas comment en obtenir) A noter: Il n\u0026rsquo;y a pas de free tier propos√© par AWS sur les instances GPU. Il est essentiel de bien √©teindre ou d√©truire ta VM une fois la session termin√©e afin √©viter d\u0026rsquo;√™tre factur√© pour des heures inutilis√©es\u0026hellip; Infrastructure cible #Mon template CloudFormation permet de g√©n√©rer :\nUn VPC d√©di√© Un subnet public Une instance EC2 g4adn.xlarge avec le syst√®me sur un disque SSD, avec un volume HDD (st1) mont√© pour stocker les jeux Je me suis bas√© sur l\u0026rsquo;ami Microsoft Windows Server 2019 with AMD Radeon Pro Driver propos√©e gratuitement par AWS pour g√©n√©rer mon template. Elle est pr√©configur√©e avec les drivers AMD pr√©install√©s (pratique).\nLes disques st1 sont relativement lents, mais peu cher. J\u0026rsquo;ai choisi cette option ici afin de tester ma config, mais il est conseill√© d\u0026rsquo;utiliser un stockage SSD pour jouer confortablement. D√©ploiement #Quotas de services #Les instances G4 AWS n√©cessitent des quotas pour √™tre provisionn√©es. Par d√©faut, sur ce type d\u0026rsquo;instance, le quota est de 0. Si tu essayes de provisionner une machine G4 en ayant 0 quota, √ßa ne marchera pas. Pour ce faire, connecte toi √† la console AWS et tape service quotas dans la barre de recherche et choisi EC2 :\nDans la barre de recherche sur l\u0026rsquo;√©cran suivant, tape \u0026ldquo;G4\u0026rdquo; et suit les instructions pour augmenter le quota. Le quota correspond au nombres de vCPU allou√©es √† une instance. Pour la g4ad.xlarge, il nous faut 4 vCPU. Changer la valeur du quota par 4, et envoyer.\nIl n\u0026rsquo;est pas possible d\u0026rsquo;obtenir des quotas pour des host dedicated avec un compte AWS personnel qui a peu servi. Apr√®s avoir fait la demande, le service client d\u0026rsquo;AWS la refusera, et te proposera des quotas pour des instances de type spot ou on-demand. J\u0026rsquo;ai demand√© d\u0026rsquo;avoir acc√®s aux instances on-demand suite √† ma premi√®re requ√™te, celles-ci furent disponible le lendemain. D√©ploiement de l\u0026rsquo;EC2 #Si ce n\u0026rsquo;est pas d√©j√† fais, authentifie toi √† awscli. Si tu as besoin d\u0026rsquo;aide, la doc d\u0026rsquo;Amazon est vraiment bien faite.\n√âtant sous MacOS, les commandes suivantes devraient fonctionner sous Linux et MacOS. Si tu es sous Windows, je te conseille de passer via WSL pour b√©n√©ficier d\u0026rsquo;un shell bash. Mon template utilise une KeyPair appel√©e CloudGamingKeyPair permettant de decrypter le mot de passe administrateur de l\u0026rsquo;instance. Pour la cr√©er :\nmkdir ~/.ssh/aws-private-keys \u0026amp;\u0026amp; cd ~/.ssh/aws-private-keys aws ec2 create-key-pair \\ --key-name CloudGamingKeyPair \\ --query \u0026#39;KeyMaterial\u0026#39; \\ --region eu-west-2 \\ --output text \u0026gt; CloudGamingKeyPair.pem Clone mon repo et ce rendre dans le dossier contenant le template :\ngit clone https://github.com/fabienchevalier/ec2-cloudgaming \u0026amp;\u0026amp; cd cloudformation Ouvre le template avec un editeur de texte, et modifie les lignes 60 et 64 en remplacant l\u0026rsquo;adresse par ton adresse IP.\nSecurityGroupIngress: - IpProtocol: tcp FromPort: 8443 #NICE DVC Server ToPort: 8443 CidrIp: 0.0.0.0/0 #Replace that with your IP address (mask should be /32) - IpProtocol: tcp FromPort: 3389 ToPort: 3389 CidrIp: 0.0.0.0/0 #Repl 0.0.0.0/0 autorise n\u0026rsquo;importe quelle adresse sur le port RDP et NICE DCV Server, ce qui n\u0026rsquo;est pas souhaitable.\nTip: tu peux r√©cup√©rer ton adresse ip public via curl ifconfig.me D√©ploie le template CloudFormation :\naws --region eu-west-2 cloudformation deploy \\ --template deploy-cloud-gaming-ec2.cfn.yaml \\ --stack-name CloudGamingStack Il est possible de suivre l\u0026rsquo;avancement de la cr√©ation de la stack sur la console AWS, via la page CloudFormation : Une fois l\u0026rsquo;instance d√©ploy√©e, il faut r√©cup√©rer le mot de passe Administrateur permettant une premi√®re connexion via le protocole RDP.\nOn r√©cup√®re l\u0026rsquo;ID de l\u0026rsquo;instance cr√©e :\naws --region eu-west-2 ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=CloudGamingInstance\u0026#34; \\ --query \u0026#39;Reservations[].Instances[].[InstanceId]\u0026#39; \\ --output text Copier l\u0026rsquo;ID g√©n√©r√© puis :\naws ec2 get-password-data --instance-id i-1234567890abcdef0 \\ --priv-launch-key ~/.ssh/aws-private-keys/CloudGamingKeyPair.pem Le mot de passe Administrateur se situe dans le champ PasswordData de l\u0026rsquo;output, par exemple :\n{ \u0026#34;InstanceId\u0026#34;: \u0026#34;i-1234567890abcdef0\u0026#34;, \u0026#34;Timestamp\u0026#34;: \u0026#34;2013-08-30T23:18:05.000Z\u0026#34;,z \u0026#34;PasswordData\u0026#34;: \u0026#34;\u0026amp;ViJ652e*u\u0026#34; } On y est presque!\nConfiguration de l\u0026rsquo;instance #Disque dur #Une premi√®re connexion via RDP est n√©cessaire afin de configurer quelques derniers d√©tails. Pour ce faire, lance un client RDP (Microsoft Remote Desktop sous MacOS pour ma part) et connecte toi √† l\u0026rsquo;instance via son IP publique.\nUtilise les informations de login r√©cup√©r√©es auparavant (login Administrator, mot de passe donn√© par la commande ec2 get-password-data) pour te connecter. Cherches disk manager dans la barre de recherche Windows, et formate le disque cr√©√© par le template CloudFormation comme ceci :\nChoisir l\u0026rsquo;option New Simple Volume, et formater l\u0026rsquo;ensemble de l\u0026rsquo;espace disque disponible.\nServeur Nice DCV #Il nous reste √† d√©ployer le serveur Nice DCV permettant de streamer sans latences depuis l\u0026rsquo;instance EC2. Pour ce faire, il faudra se connecter une premi√®re fois en RDP via l\u0026rsquo;adresse IP publique de l\u0026rsquo;EC2 afin d\u0026rsquo;executer ce script PowerShell :\n# Set TLS 1.2 for Invoke-RestMethod [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 # Set the download link to Nice DCV Server (64-bit installer) $downloadUrl = \u0026#34;https://d1uj6qtbmh3dt5.cloudfront.net/nice-dcv-server-x64-Release.msi\u0026#34; # Set the path for our download, which will be in the temp directory $installerFile = \u0026#34;nice-dcv-server-x64-Release.msi\u0026#34; $installerDownloadPath = (Join-Path $env:TEMP $installerFile) # Set the default owner to the current user $installerOwner = [Environment]::UserName # Set Install Command Expression $msiExpression = \u0026#34;msiexec.exe /i $installerDownloadPath AUTOMATIC_SESSION_OWNER=$installerOwner ADDLOCAL=ALL /quiet /norestart /l*v dcv_install_msi.log\u0026#34; # Download the file Invoke-Webrequest $downloadUrl -UseBasicParsing -OutFile $installerDownloadPath # Install Invoke-Expression $msiExpression Pour ce faire, copie/colle ce script dans le notepad de l\u0026rsquo;instance, et enregistre le fichier sur le bureau :\nPuis, clic droit sur l\u0026rsquo;ic√¥ne, puis Run with PowerShell. Attendre une ou deux minutes apr√®s que la fen√™tre se ferme, le temps que le serveur se lance.\nThat\u0026rsquo;s it! Une fois le serveur d√©ploy√©, tu peux fermer ta connexion RDP, et t√©l√©charger le client Nice DCV.\nConnexion √† l\u0026rsquo;instance via Nice DCV #Lance le client, et connecte toi via l\u0026rsquo;adresse IP publique de ton instance, sur le port 8443:\nUne erreur de certificat peut appara√Ætre, clique sur Trust \u0026amp; Connect\nA partir de l√†, libre √† toi d\u0026rsquo;installer tes jeux et de commencer √† jouer !\nJe te conseilles de d√©sactiver le mode de s√©curit√© d\u0026rsquo;IE, navigateur par d√©faut sur Windows Server (h√© oui\u0026hellip;) puis d\u0026rsquo;installer un navigateur r√©cent. Quelques am√©liorations #Par d√©faut, le serveur NICE DCV streame 25 FPS. C\u0026rsquo;est configurable via le registre Windows, via la cl√©e situ√©e ici : HKEY_CURRENT_USER\\Software\\GSettings\\com\\nicesoftware\\dcv. Cr√©er une nouvelle cl√©e display et lui donner pour valeur (type DWORD 32bits) le nombre de FPS souhait√©.\nConclusion #Apr√®s quelques heures d\u0026rsquo;essais, le confort de jeu est plut√¥t bon. Pas trop de latences, m√™me en WiFi. La qualit√© d\u0026rsquo;image est aussi plut√¥t bonne.\nCependant, le co√ªt engendr√© par l\u0026rsquo;utilisation de l\u0026rsquo;EC2 reste trop √©lev√© √† mon sens pour que cela soit viable. En effet, il faut ajouter au prix horaire de l\u0026rsquo;instance :\nLe stockage (assez cher si on choisit de passer par du SSD : +/- 11$/mois) La bande passante : pay√©e au Go, √ßa peut vite s\u0026rsquo;envoler pour du stream 4K@60FPS. Cela dit, cette m√©thode de tarification √† l\u0026rsquo;heure peut convenir √† des joueurs occasionels ne voulant pas s\u0026rsquo;abonner √† un service qu\u0026rsquo;ils utiliserons que tr√®s peu.\nIl est aussi possible d\u0026rsquo;utiliser Parsec pour streamer le contenu du serveur, mais dans sa version gratuite la r√©solution maximale est de 1080p. Si tu remarques des fautes ou quelque chose qui ne fonctionne pas, n\u0026rsquo;h√©sites pas √† le mentionner dans les commentaires !\nA bient√¥t !\n","date":"30 mars 2023","permalink":"/blog/informatique/aws-ec2-cloudgaming-instance/","section":"Blog","summary":"Provisionner facilement son instance gaming en utilisant CloudFormation et NICE DCV Server sur le cloud AWS.","title":"Provisionner sa propre instance de jeu Windows Server dans le cloud AWS via CloudFormation"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/windows-server-2019/","section":"Tags","summary":"","title":"Windows-Server-2019"},{"content":"","date":null,"permalink":"/tags/appservices/","section":"Tags","summary":"","title":"Appservices"},{"content":"","date":null,"permalink":"/tags/azure/","section":"Tags","summary":"","title":"Azure"},{"content":"","date":null,"permalink":"/categories/azure/","section":"Categories","summary":"","title":"Azure"},{"content":"","date":null,"permalink":"/tags/azuremanagedsql/","section":"Tags","summary":"","title":"Azuremanagedsql"},{"content":"Pr√©requis # Un compte Azure (ici j\u0026rsquo;utilise mon compte Azure Student) Terraform AzureCLI Un compte de stockage Azure, avec un containeur permettant de stocker le terraform.tfstate Dans mon cas, j\u0026rsquo;ai cr√©√© un groupe de ressource d√©di√© √† mon backend via le portail Azure, puis le compte de stockage dans ce groupe :\nCi ce n\u0026rsquo;est pas d√©j√† fait, il faut t\u0026rsquo;authentifier √† Azure via la commande az login et suivre les instructions.\nObjectif #L\u0026rsquo;objectif de cet article est d\u0026rsquo;expliquer la mise en place d\u0026rsquo;une instance GLPI dans le cloud Azure, et de sa base de donn√©e MySQL en utilisant des services manag√©s propos√©s par Microsoft. L\u0026rsquo;int√©gralit√© du code est disponible ce repo . Cet article est bas√© sur le d√©ploiement de GLPI, mais devrais fonctionner avec n\u0026rsquo;importe quelle application web fonctionnant avec une base de donn√©e MySQL.\nInfrastructure cible #Pour d√©ployer notre instance de test, nous allons (dans l\u0026rsquo;ordre) d√©finir :\nUn groupe de ressource Azure qui va contenir l\u0026rsquo;ensemble des ressources Un VPC (Virtual Network sur Azure) 2 subnets : un d√©di√© √† la base de donn√©es, l\u0026rsquo;autre √† l\u0026rsquo;application web. Un serveur manag√© Azure mysql flexible (plan Bs1) Une base de donn√©e manag√©e Azure SQL Un plan App Service Linux (B1) Une App Service Linux Une r√®gle de pare-feu autorisant les instances Azure √† acc√©der √† la base de donn√©e. La base de donn√©e ne sera pas accessible via le web, mais uniquement via notre VPC. En fin de compte, l\u0026rsquo;architecture devrais ressembler √† ceci :\nTerraform #Structure #Notre code Terraform se d√©compose en 3 fichiers :\n‚îú‚îÄ‚îÄ inputs.tf ‚îú‚îÄ‚îÄ main.tf ‚îî‚îÄ‚îÄ outputs.tf inputs.tfd√©finit les variables d\u0026rsquo;entr√©es (adressage, nom des ressources etc). inputs.tf outputs.tfpermet d\u0026rsquo;afficher les donn√©es n√©cessaires pour se connecter √† notre app une fois le d√©ploiement termin√©. outputs.tf main.tf contient l\u0026rsquo;ensemble du code provisionnant l\u0026rsquo;infrastructure. Je vais le d√©tailler ci-dessous. Configuration du backend #Au d√©but du fichier main.tf, je configure le provider Terraform azurerm, en lui indiquant o√π stocker le fichier terraform.statepermettant de garder en m√©moire la configuration de l\u0026rsquo;infrastructure :\nterraform { backend \u0026#34;azurerm\u0026#34; { resource_group_name = \u0026#34;backend-terraform-rg\u0026#34; storage_account_name = \u0026#34;terraformbackend9809\u0026#34; container_name = \u0026#34;terraform\u0026#34; key = \u0026#34;terraform.tfstate\u0026#34; } required_providers { azurerm = { source = \u0026#34;hashicorp/azurerm\u0026#34; version = \u0026#34;~\u0026gt; 3.47.0\u0026#34; } } required_version = \u0026#34;\u0026gt;= 1.4.0\u0026#34; } provider \u0026#34;azurerm\u0026#34; { features {} } Cr√©ation du groupe de ressource #Pour cr√©er des ressources dans Azure, il faut cr√©er un groupe de ressources :\n# Resource Group resource \u0026#34;azurerm_resource_group\u0026#34; \u0026#34;rg\u0026#34; { name = var.resource_group_name location = var.location } A noter: le code reprends les variables d√©finies dans le fichier inputs.tf. Il en va de m√™me pour les exemples suivants. Cr√©ation du VPC et des sous-r√©seaux #L\u0026rsquo;exemple de code ci-dessous cr√©e un VPC, et deux sous r√©seaux. Un pour la base de donn√©e, et un pour l\u0026rsquo;application web :\n# Virtual Network and subnet resource \u0026#34;azurerm_virtual_network\u0026#34; \u0026#34;vnet\u0026#34; { name = var.vnet_name address_space = var.vnet_address_space location = var.location resource_group_name = azurerm_resource_group.rg.name } resource \u0026#34;azurerm_subnet\u0026#34; \u0026#34;mysql_subnet\u0026#34; { name = var.mysql_subnet_name resource_group_name = azurerm_resource_group.rg.name virtual_network_name = azurerm_virtual_network.vnet.name address_prefixes = var.mysql_subnet_address_prefixes service_endpoints = [\u0026#34;Microsoft.Sql\u0026#34;] delegation { name = \u0026#34;vnet-delegation\u0026#34; service_delegation { name = \u0026#34;Microsoft.DBforMySQL/flexibleServers\u0026#34; actions = [ \u0026#34;Microsoft.Network/virtualNetworks/subnets/action\u0026#34; ] } } } resource \u0026#34;azurerm_subnet\u0026#34; \u0026#34;app_service_subnet\u0026#34; { name = var.app_subnet_name resource_group_name = azurerm_resource_group.rg.name virtual_network_name = azurerm_virtual_network.vnet.name address_prefixes = var.app_subnet_address_prefixes delegation { name = \u0026#34;vnet-delegation\u0026#34; service_delegation { name = \u0026#34;Microsoft.Web/serverFarms\u0026#34; actions = [\u0026#34;Microsoft.Network/virtualNetworks/subnets/action\u0026#34;] } } } Les d√©l√©gations configur√©es dans les blocs delegationet service_delegationpermettent de designer ces subnets en tant que cibles pour des ressources PaaS Azure. Serveur de base de donn√©e SQL #J\u0026rsquo;ai choisi de d√©ployer une base de donn√©e de type flexible, en utilisant le plan B_Standard_B1s. C\u0026rsquo;est suffisant pour notre infrastructure, et peu on√©reux. Le tableau des tarifs est disponible ici.\nresource \u0026#34;azurerm_mysql_flexible_server\u0026#34; \u0026#34;mysql\u0026#34; { name = var.mysql_server_name location = azurerm_resource_group.rg.location resource_group_name = azurerm_resource_group.rg.name administrator_login = var.mysql_database_admin_username administrator_password = random_password.mysql_password.result backup_retention_days = 5 sku_name = \u0026#34;B_Standard_B1s\u0026#34; delegated_subnet_id = azurerm_subnet.mysql_subnet.id } Le mot de passe administrateur est g√©n√©r√© al√©atoirement et sera affich√© dans les output apr√®s avoir d√©ploy√© l\u0026rsquo;infrastructure. L\u0026rsquo;option\u0026rsquo; delegated_subnet_id permet d\u0026rsquo;attacher ce serveur au subnet pr√©c√©dement cr√©√©.\nBase de donn√©e SQL ## MySQL Database resource \u0026#34;azurerm_mysql_flexible_database\u0026#34; \u0026#34;mysql\u0026#34; { name = var.mysql_database_name resource_group_name = azurerm_resource_group.rg.name server_name = azurerm_mysql_flexible_server.mysql.name charset = \u0026#34;utf8\u0026#34; collation = \u0026#34;utf8_unicode_ci\u0026#34; } Cet extrait de code cr√©e une base de donn√©e d√©di√©e √† GLPI, sur le serveur MySQL manag√© Azure.\nR√®gles de firewall ## Firewall rule resource \u0026#34;azurerm_mysql_flexible_server_firewall_rule\u0026#34; \u0026#34;fw-mysql\u0026#34; { name = \u0026#34;AllowAzureIPs\u0026#34; resource_group_name = azurerm_resource_group.rg.name server_name = azurerm_mysql_flexible_server.mysql.name start_ip_address = \u0026#34;0.0.0.0\u0026#34; end_ip_address = \u0026#34;0.0.0.0\u0026#34; } Par convention, autoriser les ips 0.0.0.0revient √† autoriser les ressources Azure uniquement d\u0026rsquo;acc√©der √† la base de donn√©e.\nPlan Azure App Service et application App Service #resource \u0026#34;azurerm_service_plan\u0026#34; \u0026#34;glpi-service-plan\u0026#34; { name = var.glpi_app_service_plan_name resource_group_name = azurerm_resource_group.rg.name location = azurerm_resource_group.rg.location os_type = \u0026#34;Linux\u0026#34; sku_name = \u0026#34;B1\u0026#34; } resource \u0026#34;azurerm_linux_web_app\u0026#34; \u0026#34;glpi-app-service\u0026#34; { name = var.glpi_app_service_name resource_group_name = azurerm_resource_group.rg.name location = azurerm_service_plan.glpi-service-plan.location service_plan_id = azurerm_service_plan.glpi-service-plan.id site_config { always_on = false application_stack { docker_image = \u0026#34;diouxx/glpi\u0026#34; docker_image_tag = \u0026#34;latest\u0026#34; } } } #Connect the Azure App to subnet resource \u0026#34;azurerm_app_service_virtual_network_swift_connection\u0026#34; \u0026#34;app\u0026#34; { app_service_id = azurerm_linux_web_app.glpi-app-service.id subnet_id = azurerm_subnet.app_service_subnet.id } Cet extrait de code d√©ploye l\u0026rsquo;application web GLPI au sein d\u0026rsquo;un plan B1. Dans mon exemple, j\u0026rsquo;utilise une image docker GLPI h√©berg√©e sur le docker hub.\nLe plan B1 est le plan App Service le moins cher permettant d\u0026rsquo;attacher un App Service √† un subnet, et ainsi pouvoir communiquer en interne avec la base de donn√©e. D√©ploiement de l\u0026rsquo;infrastructure #Une fois le code r√©dig√© (ou t√©l√©charg√© directement depuis mon repo ), le d√©ploiement s\u0026rsquo;effectue en 3 commandes :\nterraform init terraform plan terraform apply terraform init permet de configurer le backend et r√©cup√©rer le module azurerm. La commande plan permet de passer en revue les changements apport√©s √† l\u0026rsquo;infrastructure, et apply de la d√©ployer :\nSi tout se passe bien, la sortie de la commande apply te donneras le n√©cessaire pour configurer ton app GLPI :\nLe d√©ploiement peut prendre du temps, notamment la base de donn√©e MySQL (+/- 10 minutes dans mon cas). L\u0026rsquo;App Service peut aussi mettre un certain temps avant d\u0026rsquo;√™tre accessible depuis l\u0026rsquo;adresse, le temps que l\u0026rsquo;image docker soit d√©ploy√©e. Derni√®res √©tapes de configuration #Dans l\u0026rsquo;interface d\u0026rsquo;installation de GLPI, saisir les informations donn√©es dans l\u0026rsquo;output terraform. Si tu as utilis√© mon fichier input.tf, l\u0026rsquo;utilisateur SQL sera glpi. La premi√®re tentative de connexion donnera cette erreur :\nPour la corriger, il suffit de se rendre dans les param√®tres de la BDD sur le portail Azure, et de passer le param√®tre require_secure_transportsur OFF:\nIl est normalement d√©sormais possible d\u0026rsquo;installer GLPI sur la base de donn√©e cr√©√©e pour l\u0026rsquo;occasion √† l\u0026rsquo;aide de Terraform:\nV√©rifications #Une fois l\u0026rsquo;application install√©e, on se connecte √† l\u0026rsquo;aide des identifiants par d√©faut (glpi/glpi):\nC\u0026rsquo;est fonctionnel!\nEn raison de la faible puissance de la base de donn√©e manag√©e choisie, l\u0026rsquo;affichage peut √™tre tr√®s long dans l\u0026rsquo;application. Si c\u0026rsquo;est inutilisable, ne pas h√©siter √† augmenter la taille de l\u0026rsquo;instance SQL. Suppression de l\u0026rsquo;infrastructure #Un simple terraform destroyd√©truira l\u0026rsquo;ensemble des ressources cr√©es. A ne pas oublier, le co√ªt mensuel de l\u0026rsquo;App Service peut √™tre √©lev√©.\n","date":"13 mars 2023","permalink":"/blog/informatique/azure-appservices-terraform/","section":"Blog","summary":"En prenant pour example GLPI, je t\u0026rsquo;explique comment d√©ployer une application web compl√®te as code en utilisant App Services","title":"D√©ployer GLPI 10 sur Azure App Services avec une base de donn√©e manag√©e via Terraform"},{"content":"","date":null,"permalink":"/tags/glpi/","section":"Tags","summary":"","title":"Glpi"},{"content":"","date":null,"permalink":"/tags/iac/","section":"Tags","summary":"","title":"Iac"},{"content":"","date":null,"permalink":"/tags/terraform/","section":"Tags","summary":"","title":"Terraform"},{"content":"","date":null,"permalink":"/tags/latex/","section":"Tags","summary":"","title":"Latex"},{"content":"","date":null,"permalink":"/tags/markdown/","section":"Tags","summary":"","title":"Markdown"},{"content":"","date":null,"permalink":"/categories/markdown/","section":"Categories","summary":"","title":"Markdown"},{"content":"","date":null,"permalink":"/tags/pandoc/","section":"Tags","summary":"","title":"Pandoc"},{"content":"","date":null,"permalink":"/tags/pdf/","section":"Tags","summary":"","title":"Pdf"},{"content":"Le language Markdown # Attention Cet article part du principe que vous √™tes d√©j√† √† l\u0026rsquo;aise avec la r√©daction en Markdown. Si ce n\u0026rsquo;est pas le cas, un tutorial interactif assez bien fait est disponible ici Markdown est un language de balisage facile √† utiliser et √† lire. Je m\u0026rsquo;en suis beaucoup servi lors de mes √©tudes pour prendre des notes, car Markdown permet d\u0026rsquo;obtenir un r√©sultat propre tr√®s rapidement avec un simple √©diteur de texte. Diff√©rents logiciels sont compatible avec Markdown, permettant d\u0026rsquo;organiser ses notes et d\u0026rsquo;obtenir un aper√ßu en temps r√©el lors de l\u0026rsquo;√©dition. Personnellement, j\u0026rsquo;utilise Bear sous MacOS:\nInterface principal de Bear, avec le texte format√© en utilisant Markdown Markdown est aussi extr√™mement r√©pandu dans le monde de l\u0026rsquo;informatique, la majorit√© des fichiers README √©tant r√©dig√© en utilisant la syntaxe Markdown.\nLes limites du Markdown #J\u0026rsquo;ai tellement pris l\u0026rsquo;habitude de r√©diger mes documentations et notes en Markdown, que √ßa soit sur VS Code ou sur des applications type Bear, que l\u0026rsquo;utilisation de Word me para√Æt d√©sormais extr√™mement lourde et contre-productive. Le souci, c\u0026rsquo;est que par d√©faut, Markdown n\u0026rsquo;est pas pr√©vu pour g√©n√©rer des documents imprimables. En effet, c\u0026rsquo;est uniquement un language de balisage, con√ßu pour √™tre interpr√©t√© et affich√© √† l\u0026rsquo;√©cran.\nG√©n√©rer un document type \u0026ldquo;M√©moire\u0026rdquo; depuis des fichiers Markdown #Je me suis bas√© sur ce repo pour cr√©er un template (en Fran√ßais) permettant de g√©n√©rer un document adapt√© √† mes rendus d\u0026rsquo;√©cole. Concr√®tement, il s\u0026rsquo;agit ici d\u0026rsquo;utiliser Pandoc associ√© √† un template LaTeX permettant de g√©n√©rer le document. Rassurez-vous, il n\u0026rsquo;est pas n√©cessaire d\u0026rsquo;apprendre LaTeX pour utiliser ce projet, seule certaines commandes suffisent.\n√âtape 1 #R√©cup√©rer sur mon GitHub le template :\ngit clone https://github.com/fabienchevalier/phd_thesis_markdown.git Pandoc n√©cessite LaTeX pour g√©n√©rer des PDF. En fonction de votre OS, il faut donc installer une distribution LaTeX:\nLinux: sudo apt-get install textlive Windows: voir du c√¥t√© de MiKTex MacOS: via homebrew avec brew install --cask mactex Par la suite, mettre √† jour sa distribution LaTeX:\nsudo tlmgr update --self √âtape 2 #Installer Pandoc dans un environnement Python s√©par√©. Personnellement, j\u0026rsquo;utilise miniconda sous MacOS (disponible aussi sur Linux/Windows):\nbrew install miniconda #apt-get install miniconda devrais fonctionner sous Ubuntu/Debian conda create -n phd -y python=3.7 pandoc conda activate phd Les autres d√©pendances peuvent √™tre install√©es automatiquement via le Makefile propos√© :\nmake install √âtape 3 #Par la suite, d√©poser les fichiers md dans le dossier source et executer make pdf pour g√©n√©rer le document au format PDF. Ne pas oublier de modifier le fichier metadata.yml dans le dossier source en fonction des besoins! Un exemple de rendu est disponible ici.\n","date":"7 f√©vrier 2023","permalink":"/blog/informatique/markdown-to-pdf-latex/","section":"Blog","summary":"Comment g√©n√©rer un document type \u0026ldquo;M√©moire\u0026rdquo; au format PDF depuis des fichiers Markdown en utilisant LaTeX et Pandoc","title":"R√©diger son m√©moire universitaire en Markdown"},{"content":" R√©alis√© dans le cadre de mes deux ann√©es de BTS, ce portofolio r√©sume les travaux entrepris lors de ces deux ann√©es d\u0026rsquo;√©tude. Enti√®rement r√©alis√© en Markdown, ce site web est h√©berg√© par GitHub et √† √©t√© construit √† partir du template Jekyll Minimal Mistake.\nhttps://fchevalier.net/bts\n","date":"1 septembre 2022","permalink":"/projets/bts_sio/","section":"Projets","summary":"R√©alis√© dans le cadre de mes deux ann√©es de BTS, ce portofolio r√©sume les travaux entrepris lors de ces deux ann√©es d\u0026rsquo;√©tude.","title":"Portofolio BTS SIO SISR"}]
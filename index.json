[{"content":"Hi üëã #üè¢ DevOps @Claranet France\nüìã Mon CV\n","date":null,"permalink":"/","section":"/home","summary":"","title":"/home"},{"content":" C\u0026rsquo;est ici que je publie mes articles quand le temps me le permet. üìå Articles r√©cents #","date":null,"permalink":"/blog/","section":"Blog","summary":"","title":"Blog"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/tags/cloud/","section":"Tags","summary":"","title":"Cloud"},{"content":"","date":null,"permalink":"/tags/dry/","section":"Tags","summary":"","title":"Dry"},{"content":"","date":null,"permalink":"/categories/iac/","section":"Categories","summary":"","title":"Iac"},{"content":"","date":null,"permalink":"/tags/iac/","section":"Tags","summary":"","title":"Iac"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/categories/terraform/","section":"Categories","summary":"","title":"Terraform"},{"content":"","date":null,"permalink":"/tags/terraform/","section":"Tags","summary":"","title":"Terraform"},{"content":"","date":null,"permalink":"/tags/terragrunt/","section":"Tags","summary":"","title":"Terragrunt"},{"content":" Nouvel article! Terragrunt est un wrapper (surcouche) pour Terraform, con√ßu pour simplifier et optimiser la gestion des configurations d\u0026rsquo;infrastructure en suivant le principe DRY (Don\u0026rsquo;t Repeat Yourself). Dans cet article, je vais tenter d\u0026rsquo;expliquer le fonctionnement de Terragrunt √† travers un cas client fictif. Depuis la cr√©ation du clone open-source de Terraform, √† savoir OpenTofu, Terragrunt utilisera par d√©faut OpenTofu si il est install√© sur ta machine. Dans cet article, je me base sur Terraform mais la logique reste la m√™me. Introduction #Reprenant les bonnes pratiques issues du monde du d√©veloppement, Terragrunt permet de r√©duire la duplication de code en factorisant les configurations Terraform. Cet article √† pour but d\u0026rsquo;expliquer la mise en place d\u0026rsquo;un projet Terraform avec Terragrunt, et surtout de comprendre l√† o√π Terragrunt apporte de la valeur par rapport √† Terraform seul. Attention, Terragrunt n√©cessite des bases solides en configurations Terraform, cet article se destine donc √† un public ayant d√©j√† pratiqu√© Terraform sur des infrastructures moyennes √† grandes, et souhaitant en optimiser la gestion afin de passer √† l\u0026rsquo;√©chelle. Si ce n\u0026rsquo;est pas ton cas, je t\u0026rsquo;invite √† consulter cette section du blog de St√©phane Robert pour te familiariser avec Terraform. Tout y est tr√®s bien expliqu√©.\nContexte #J\u0026rsquo;ai √©t√© amen√© √† travailler pour un client ayant une infrastructure cloud cons√©quente, et logiquement beaucoup de ressources √† g√©rer. La principale probl√©matique rencontr√©e dans la gestion d\u0026rsquo;une architecture de cette taille avec Terraform est pour moi l\u0026rsquo;organisation m√™me du code, et la dette technique qui en d√©coule. En effet, √† force de multiplier les ressources, variables, environnements etc.. , on peut vite se retrouver avec du code difficile √† comprendre et maintenir, surtout lors de phases de build avec des deadlines serr√©es.\nTerragrunt se veut √™tre une r√©ponse efficace √† ces probl√©matiques en apportant une organisation claire et modulaire au code Terraform. En externalisant les param√®tres sp√©cifiques √† chaque environnement et en automatisant la gestion des d√©pendances entre modules, Terragrunt offre une solution structur√©e pour minimiser la dette technique.\nIllustration de circonstance : Plan B est un jeu proposant de \u0026hellip; Terraformer une plan√®te. Cool, non ? Cependant, son adoption n\u0026rsquo;est pas forc√©ment pertinente pour des projets de petite taille, et peut m√™me √™tre contre-productive si mal utilis√©e (üëã Kubernetes). De plus, la courbe d\u0026rsquo;apprentissage peut √™tre assez raide, j\u0026rsquo;en ai fais les frais.\nComprendre les concepts de modularit√©, d‚Äôh√©ritage de configurations ou encore de gestion des d√©pendances demande un investissement initial non n√©gligeable. Cela dit, une fois compris et bien utilis√©, Terragrunt peut vite se r√©v√©ler indispensable. Il permet de structurer efficacement des projets complexes, et de r√©duire la duplication de code (factorisation) de mani√®re √©l√©gante.\nDans cet article, je vais donc tenter de t\u0026rsquo;expliquer une mani√®re d\u0026rsquo;utiliser Terragrunt, √† travers un exemple fictif. Je pense qu\u0026rsquo;il est plus facile d\u0026rsquo;int√©grer certains concepts appliqu√©s √† une situation concr√®te, plut√¥t que de se plonger dans la th√©orie. Apr√®s tout, la doc officielle est (tr√®s) bien √©crite üôÉ.\nJe pr√©sente ici une m√©thode d\u0026rsquo;utilisation de Terragrunt, et non LA m√©thode. A tes risques et p√©rils üòé. Les exemples que je vais fournir se basent sur des configurations GCP, mais la logique est applicable √† n\u0026rsquo;importe quel cloud provider. Il ne s\u0026rsquo;agira pas ici d\u0026rsquo;expliquer comment bootstrap tel ou tel ressources, mais plut√¥t de te montrer comment organiser ton code Terraform avec Terragrunt.\nC\u0026rsquo;est quoi concr√®tement, Terragrunt # Sch√©ma repr√©sentatif d\u0026rsquo;une configuration Terragrunt, issu du site de Terragrunt Terragrunt est avant-tout un outil CLI, reprenant la syntaxe de Terraform dans son fonctionnement ad-hoc. On retrouvera donc les fameux terragrunt plan, terragrunt apply, etc.. L√† o√π √ßa devient int√©ressant, c\u0026rsquo;est que Terragrunt propose en sus des fonctionnalit√©s comme la g√©n√©ration dynamiques de fichiers backend.tf (oui, il permet aussi de cr√©er le bucket √† la vol√©e si celui-ci n\u0026rsquo;existe pas), des fonctions permettant de manipuler des fichiers HCL (comme read_terragrunt_config), ou encore une gestion avanc√©e des d√©pendances entre modules.\nJe te recommande de lire au moins le d√©but du quickstart Terragrunt pr√©sent dans la documentation officielle. Cela t\u0026rsquo;aideras grandement √† comprendre les concepts d√©taill√©s par la suite dans cet article. L\u0026rsquo;organisation du code #L\u0026rsquo;organisation du code, ainsi que l\u0026rsquo;architecture des dossiers sont extr√™mement importante. Encore une fois, l\u0026rsquo;usage de Terragrunt permet de forcer des bonnes pratiques, mais un mauvais choix d\u0026rsquo;organisation peut vite se r√©v√©ler cauchemardesque, en particulier avec Terragrunt. Pour cet article, je vais donc choisir de baser mes explications sur le cas d\u0026rsquo;un client fictif, mais qui se rapproche de ce que j\u0026rsquo;ai pu voir dans le monde r√©el.\nContexte client #Partons du principe suivant : je souhaite h√©berger pour le compte d\u0026rsquo;un client une application 3 tiers classique, afin d\u0026rsquo;h√©berger une marketplace. Niveau ressources cloud, on aura donc besoin de :\nJe travaille beaucoup sur GCP en ce moment, pour simplifier la r√©daction de mon article, je me base donc sur des assets GCP. Configurer un r√©seau VPC (subneting, firewall rules, etc..). Mettre en place une base de donn√©es D√©ployer une application web (front + back), dans mon exemple contain√©ris√©e Mettre en place un load balancer et un orchestrateur de conteneurs, par facilit√©e je vais ici utiliser CloudRun. On parle d\u0026rsquo;IaC, il va donc falloir cr√©er et organiser son code via des repos Git. Les d√©veloppeurs vont travailler sur leurs repos respectifs, √† savoir marketplace-frontend et marketplace-backend. En parall√®le, il va falloir cr√©er un repo appel√© marketplace-infrastructure permettant de d√©finir l\u0026rsquo;infrastructure permettant d\u0026rsquo;h√©berger l\u0026rsquo;application (base de donn√©es, load balancer, etc..). Enfin, un repo infrastructure-shared-modules sera cr√©√© afin de g√©rer et versionner nos modules. Je ne vais pas m\u0026rsquo;attarder sur les questions de CI/CD et autres, ce n\u0026rsquo;est pas le sujet ici.\nJe ne fournirais pas le code des modules, ni m√™me la configuration compl√®te de l\u0026rsquo;infrastructure. Je me limite ici uniquement √† l\u0026rsquo;abstraction Terragrunt. J\u0026rsquo;ai cependant r√©dig√© un article d√©taillant la mise en place compl√®te d\u0026rsquo;une infrastructure via Terraform disponible ici. Sch√©ma d\u0026rsquo;architecture #Pour contextualiser un peu tout √ßa, voici un sch√©ma d\u0026rsquo;architecture basique repr√©sentant les briques √† d√©ployer :\nSch√©ma de l\u0026rsquo;architecture de l\u0026rsquo;application D\u0026rsquo;un premier abord, dans le cas o√π mon client fictif ne souhaite utiliser que deux environnements de d√©veloppement, pour ce projet unique, Terragrunt serais overkill. Imaginons maintenant que ce m√™me client souhaite 4 environnements, √† savoir dev, staging, preprod et prod. De plus, il viens de recevoir une demande du m√©tier, n√©cessitant la mise en place de 6 applications similaires. Tu vois ou je veux en venir ?\nHi√©rarchie des dossiers # La logique d\u0026rsquo;organisation des dossiers est directement inspir√©e de l\u0026rsquo;excellent repo maintenu par Padok, fournissant des bonnes pratiques sur l\u0026rsquo;utilisation de Terraform, et notamment le concept de layers. Je t\u0026rsquo;invites √† le consulter. Je sais donc que je dois livrer la marketplace en premier lieu, sur 4 environnements, mais avec en t√™te le fait que quelques semaines plus tard la demande √©voluera. L√†, on rentre dans un cas ou Terragrunt pourra m\u0026rsquo;√™tre utile, car je vais pouvoir factoriser d√®s le d√©but.\nPour illustrer mon explication, je vais me concentrer sur deux briques de l\u0026rsquo;architecture, √† savoir le load balancer et le cloud run. Bien s√ªr, il faudra configurer bien plus de ressources afin de rendre mon architecture fonctionnelle, mais je cherche ici √† expliquer la logique de factorisation induite par Terragrunt.\nLe repo marketplace-infrastructure #Voici l\u0026rsquo;architecture de dossier propos√©e :\n‚îî‚îÄ‚îÄ layers ‚îú‚îÄ‚îÄ cloud-run ‚îÇ ‚îú‚îÄ‚îÄ marketplace-frontend | | ‚îú‚îÄ‚îÄ dev | | ‚îú‚îÄ‚îÄ staging | | ‚îú‚îÄ‚îÄ preprod | | ‚îî‚îÄ‚îÄ prod | |‚îÄ‚îÄ marketplace-backend | ‚îú‚îÄ‚îÄ dev | ‚îú‚îÄ‚îÄ staging | ‚îú‚îÄ‚îÄ preprod | ‚îî‚îÄ‚îÄ prod ‚îî‚îÄ‚îÄ load-balancer ‚îú‚îÄ‚îÄ dev ‚îú‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ preprod ‚îî‚îÄ‚îÄ prod etc etc... Ma ressource cloud-run permettra de d√©ployer les deux services de mon application, √† savoir le frontend et le backend. Je vais donc cr√©er un dossier cloud-run, contenant deux sous-dossiers, un pour chaque service. Chaque service contiendra les environnements de d√©veloppement, staging, preprod et prod.\nLe dossier load-balancer contiendra lui aussi les environnements de d√©veloppement, staging, preprod et prod.\nLe repo infrastructure-shared-modules #Le mot-cl√© factorisation reviens souvent dans cet article. On a parl√© plus haut d\u0026rsquo;un futur besoin pour mon client d\u0026rsquo;ajouter de nouvelles applications. Au lieu d\u0026rsquo;avoir √† r√©√©crire (ou copier/coller) le code de chaque module, lors de la cr√©ation d\u0026rsquo;une nouvelle application, autant tout rassembler au m√™me endroit dans un repo s√©par√©. Je le hi√©rarchise de cette mani√®re :\n‚îî‚îÄ‚îÄ modules ‚îú‚îÄ‚îÄ cloud-run ‚îú‚îÄ‚îÄ load-balancer ‚îú‚îÄ‚îÄ vpc etc etc... Ok, nous avons √† pr√©sent nos deux repo, ainsi qu\u0026rsquo;une architecture de dossier claire et facile √† comprendre. Passons aux fichiers de configuration.\nFichiers de configurations Terragrunt #Au sein du dossier layers, dans le repo marketplace-infrastructure √† la racine, je vais cr√©er un fichier root.hcl (le fichier de configuration Terragrunt racine).\nTerragrunt fonctionne de mani√®re r√©cursive. Si tu appliques la configuration Terragrunt du dossier layers/load-balancer/dev/terragrunt.hcl, il va remonter dans l\u0026rsquo;arborescence jusqu\u0026rsquo;√† trouver le fichier root.hcl et l\u0026rsquo;injecter dans la configuration. Le nommage est ici est compl√®tement arbitraire, mais sache que Terragrunt √† besoin d\u0026rsquo;au moins un fichier appel√© terragrunt.hcl √† la racine de chacune de tes stacks.\nLe concept de stack dans Terragrunt repr√©sente une unit√© de d√©ploiement. Chaque stack correspond √† un environnement sp√©cifique (par exemple, dev, staging, prod) et peut contenir plusieurs modules ou ressources. En d\u0026rsquo;autres termes, une stack est une collection de ressources Terraform qui sont g√©r√©es ensemble. Fonctions Terragrunt #Terragrunt propose un certain nombre de fonctions permettant de manipuler les fichiers de configuration, de la m√™me mani√®re que les fonctions natives Terraform. J\u0026rsquo;en utilise quelques unes dans cet article. Sans aller dans le d√©tail, Terragrunt propose des fonctions suppl√©mentaires, plus globales permettant de r√©cup√©rer du contexte de fa√ßon dynamique. Des exemples sont donn√©s et expliqu√©s dans les sections suivantes. Tu peux retrouver l\u0026rsquo;ensemble de ces fonctions document√©es ici : Terragrunt Built-in Functions.\nConfiguration des locals #Dans root.hcl, on va d√©finir d√©finir des locals, c\u0026rsquo;est √† dire des expressions communes √† l\u0026rsquo;ensemble de mes environnements dans un contexte Terraform. On y retrouvera donc l\u0026rsquo;id du projet, la region, et autres. Voici un exemple :\n# root.hcl locals { env_name = basename(get_original_terragrunt_dir()) region = \u0026#34;europe-west2\u0026#34; env_config = lookup(local.env_settings, local.env_config, {}) env_settings = { dev = { project_id = \u0026#34;marketplace-dev\u0026#34; vpc = \u0026#34;marketplace\u0026#34; labels = { environment = \u0026#34;dev\u0026#34; application = \u0026#34;marketplace\u0026#34; managed_by = \u0026#34;terraform\u0026#34; } }, staging = { project_id = \u0026#34;marketplace-staging\u0026#34; vpc = \u0026#34;marketplace\u0026#34; labels = { environment = \u0026#34;staging\u0026#34; application = \u0026#34;marketplace\u0026#34; managed_by = \u0026#34;terraform\u0026#34; } }, preprod = { project_id = \u0026#34;marketplace-preprod\u0026#34; vpc = \u0026#34;marketplace\u0026#34; labels = { environment = \u0026#34;preprod\u0026#34; application = \u0026#34;marketplace\u0026#34; managed_by = \u0026#34;terraform\u0026#34; } }, prod = { project_id = \u0026#34;marketplace-prod\u0026#34; vpc = \u0026#34;marketplace\u0026#34; labels = { environment = \u0026#34;prod\u0026#34; application = \u0026#34;marketplace\u0026#34; managed_by = \u0026#34;terraform\u0026#34; } } } } inputs = {} Dans le cas ou l\u0026rsquo;on souhaite utiliser un Cloud Provider different, comme AWS par exemple, il faudra adapter la configuration des locals en fonction de la logique de nommage de ton provider. Par exemple, pour AWS, il faudra adapter le region et le project_id en fonction de la logique de nommage AWS (account_id par exemple au lieu du project_id). Ce fichier de configuration part du principe qu\u0026rsquo;un r√©seau VPC a d√©j√† √©t√© cr√©√© par projet. Ici, dans chaque environnement, on connectera les assets au r√©seau marketplace. D√©taillons un peu ce fichier :\nenv_name: ici, la fonction basename() permet d\u0026rsquo;extraire le dernier segment d\u0026rsquo;un chemin donn√©. Utilis√©e de pair avec get_original_terragrunt_dir(), elle permet d\u0026rsquo;obtenir le nom de l\u0026rsquo;environnement actuel (par exemple, dev, staging, etc.) en se basant sur le chemin du r√©pertoire o√π se situe terragrunt.hcl, toujours de mani√®re absolue.\nregion: tr√®s simple, ici la r√©gion est hardcod√©e car ne changera pas.\nenv_config : utilise lookup() (fonction Terraform) pour r√©cup√©rer la configuration de l‚Äôenvironnement actuel. Si l‚Äôenvironnement n‚Äôexiste pas dans env_settings, la valeur par d√©faut {} est utilis√©e pour √©viter les erreurs.\nenv_settings: ce bloc d√©finit une map contenant les configurations sp√©cifiques √† chaque environnement (par exemple, dev, staging, etc.). Ici, on l\u0026rsquo;utilise pour sp√©cifier de mani√®re globale le project_id et le vpc pour chaque environnement (dans l\u0026rsquo;exemple donn√©). On pourrait y ajouter d\u0026rsquo;autres configurations que l\u0026rsquo;on souhaite centraliser tel que des tags etc.\nLes fonctions lookup() et basename() sont des fonctions natives de Terraform. Terragrunt n\u0026rsquo;√©tant qu\u0026rsquo;une surcouche de Terraform, il est possible d\u0026rsquo;utiliser ces fonctions dans les fichiers de configuration Terragrunt. Au final, malgr√© la complexit√© apparente, ce fichier root.hcl ne fais que fournir des variables g√©n√©riques de fa√ßon dynamique.\nGestion du backend Terraform #A la suite de la d√©claration des locals, on va pouvoir d√©finir la configuration du backend Terraform. En effet, Terragrunt permet de g√©rer le backend de mani√®re centralis√©e, et de le g√©n√©rer automatiquement dans chaque layer. Voici un exemple de configuration :\nremote_state { backend = \u0026#34;gcs\u0026#34; # Google Cloud Storage, mais peut √™tre S3, etc. config = { encrypt = true bucket = \u0026#34;${local.project_id}-tfstates\u0026#34; project = local.project_id prefix = \u0026#34;tfstate/${path_relative_to_include()}\u0026#34; location = local.region } generate = { path = \u0026#34;backend.tf\u0026#34; if_exists = \u0026#34;skip\u0026#34; } } On va donc se retrouver avec un fichier state par environnement, et par module. Par exemple, pour le module cloud-run, on va se retrouver avec un fichier tfstate dans le bucket marketplace-dev-tfstates (pour l\u0026rsquo;environnement dev), avec le prefix tfstate/cloud-run/marketplace-frontend. Terragrunt propose aussi de g√©n√©rer le fichier provider.tf, de la m√™me mani√®re que le fichier backend.tf. Dans mon exemple, je pr√©f√®re g√©rer la configuration du provider dans chaque module, mais sache cela reste une possibilit√©.\nConfiguration d\u0026rsquo;un layer #Pour le moment donc, j\u0026rsquo;ai couvert la configuration racine, permettant de factoriser √† la base de l\u0026rsquo;arborescence. Comme dit plus haut, c\u0026rsquo;est de cette mani√®re que Terragrunt permet de construire une infrastructure en mode DRY. Descendons maintenant d\u0026rsquo;un cran dans l\u0026rsquo;arborescence, et voyons comment configurer un asset cloud-run par exemple.\nGestion des modules Terraform de fa√ßon DRY #Naviguons dans le dossier layers/cloud-run/. Son contenu sera le suivant :\n‚îî‚îÄ‚îÄ cloud-run ‚îú‚îÄ‚îÄ dev ‚îÇ ‚îú‚îÄ‚îÄ inputs.hcl ‚îÇ ‚îî‚îÄ‚îÄ terragrunt.hcl ‚îú‚îÄ‚îÄ module.hcl ‚îú‚îÄ‚îÄ preprod ‚îÇ ‚îú‚îÄ‚îÄ inputs.hcl ‚îÇ ‚îî‚îÄ‚îÄ terragrunt.hcl ‚îú‚îÄ‚îÄ prod ‚îÇ ‚îú‚îÄ‚îÄ inputs.hcl ‚îÇ ‚îî‚îÄ‚îÄ terragrunt.hcl ‚îî‚îÄ‚îÄ staging ‚îú‚îÄ‚îÄ inputs.hcl ‚îî‚îÄ‚îÄ terragrunt.hcl Dans l\u0026rsquo;exemple fourni par Gruntwork, tout est centralis√© au sein d\u0026rsquo;un fichier unique terragrunt.hcl. En cr√©ant un fichier inputs, je me permet de s√©parer la logique de configuration de la logique d\u0026rsquo;include. C\u0026rsquo;est un choix arbitraire, mais qui me semble plus clair. M√™me chose pour le fichier module.hcl, qui source le module Terraform. Commen√ßons par le contenu du fichier module.hcl. Rappelles toi, j\u0026rsquo;ai indiqu√© en intro qu\u0026rsquo;il √©tait n√©cessaire de cr√©er un repo infrastructure-shared-modules pour y stocker mes modules. C\u0026rsquo;est ici que je vais les r√©f√©rencer :\n# module.hcl terraform { source = \u0026#34;git@github.com:my-org/infrastructure-shared-modules.git//modules/cloudrun?ref=cloudrun-v1.0.0\u0026#34; } Ici, je fais un choix. Je pourrais sourcer directement le module dans chaque terragrunt.hcl, afin d\u0026rsquo;√™tre en mesure d\u0026rsquo;avoir un module pour chaque environnement. Cela-dit, dans une logique qui se veut ISO, je pr√©f√®res que chaque environnements soient identiques √† la production. Concr√®tement, mon repo infrastructure-shared-modules va contenir l\u0026rsquo;ensemble de mes modules, versionn√©s via git.\nJe te conseilles vivement de tag tes modules, afin de pouvoir revenir en arri√®re si besoin. En effet, si tu fais √©voluer un module, et que tu ne tag pas ta version, tu risques d\u0026rsquo;appliquer les changements √† l\u0026rsquo;ensemble des configurations. En backstage, Terragrunt va cloner ce repo, et lui fournir les inputs d√©finies dans chaque fichiers inputs.hcl. On retrouvera d\u0026rsquo;ailleurs un dossier .terragrunt-cache, contenant le repo clon√© dans chaque environnement.\nQue se passe-t-il lorsque je lance un terragrunt apply ? #Un petit coup d\u0026rsquo;oeil sur le fichier terragrunt.hcl permet de se rendre compte de toute la logique expliqu√©e pr√©c√©demment :\ninclude \u0026#34;root\u0026#34; { path = find_in_parent_folders(\u0026#34;root.hcl\u0026#34;) merge_strategy = \u0026#34;deep\u0026#34; } include \u0026#34;module\u0026#34; { path = find_in_parent_folders(\u0026#34;module.hcl\u0026#34;) merge_strategy = \u0026#34;deep\u0026#34; } include \u0026#34;inputs\u0026#34; { path = \u0026#34;inputs.hcl\u0026#34; merge_strategy = \u0026#34;deep\u0026#34; } Ce qui se r√©sume sch√©matiquement :\nflowchart TD A[terragrunt.hcl] --\u003e B[root.hcl] A --\u003e C[module.hcl] A --\u003e D[inputs.hcl] Terragrunt parcourra depuis le dossier courant, et remontera dans l\u0026rsquo;arborescence jusqu\u0026rsquo;√† trouver les fichiers root.hcl; module.hcl et inputs.hcl. Il va ensuite fusionner le contenu de ces fichiers, en appliquant la strat√©gie de fusion d√©finie dans chaque include. Dans notre cas, on a choisi la strat√©gie deep, qui va permettre de fusionner les objets imbriqu√©s. La documentation de Terragrunt permettra d\u0026rsquo;en savoir plus sur les diff√©rentes strat√©gies de fusion, et le fonctionnement d\u0026rsquo;include en g√©n√©ral.\nPour faire simple, on peut partir du principe que Terragrunt va fusionner les fichiers de configuration en un seul fichier, en appliquant la strat√©gie de fusion d√©finie dans chaque include. Il va ensuite appliquer cette configuration au module Terraform. Le fichier input.hcl contiendra donc l\u0026rsquo;√©quivalent d\u0026rsquo;un fichier variables.tf dans un module Terraform classique. Il va permettre de d√©finir les variables d\u0026rsquo;entr√©es pour le module, et sera fusionn√© avec les autres fichiers de configuration. Le concept de `terragrunt run-all #Cette commande va permettre d\u0026rsquo;appliquer l\u0026rsquo;ensemble des configurations de mani√®re r√©cursive, en une seule commande. C\u0026rsquo;est bien l√† que toute la puissance de Terragrunt se r√©v√®le.\nterragrunt run-all apply layers/ En effet, si tu as bien suivi, cette commande permettra en une fois de cr√©er l\u0026rsquo;ensemble des ressources de l\u0026rsquo;application, pour chaque environnement, et d\u0026rsquo;automatiquement g√©n√©rer la configuration backend.tf.\nPour peu que tu aie les droits sur ton cloud-provider, Terragrunt se charge m√™me de cr√©er le bucket tfstates pour toi, si celui-ci n\u0026rsquo;existe pas. DRY. Il est pr√©f√©rable, dans un contexte ou des d√©pendances sont pr√©sentes, de passer par run-all afin que Terragrunt puisse correctement mettre √† jour l\u0026rsquo;√©tat des ressources. En effet, si tu appliques les configurations une par une, certaines valeurs peuvent √™tre obsol√®tes (ex. connection_string d\u0026rsquo;une base de donn√©es), et donc entra√Æner des erreurs lors de l\u0026rsquo;application des configurations. Last but not least : la gestion des d√©pendances #Tu t\u0026rsquo;es peut √™tre pos√© la question √† le lecture de cet article : si Terragrunt cherche √† appliquer une configuration d√©pendante d\u0026rsquo;une autre, comment fait-il pour savoir dans quel ordre appliquer les ressources ? En effet, si je souhaite cr√©er un cloud-run et lui permettre de se connecter √† une base de donn√©es, il faut que la base de donn√©es soit cr√©√©e avant le cloud-run. Terragrunt propose une fonctionnalit√© permettant de g√©rer les d√©pendances entre modules, et donc d\u0026rsquo;appliquer les ressources dans le bon ordre.\nAttention, Terragrunt reste un wrapper Terraform. Pour que le syst√®me de d√©pendances fonctionne, il faut que tes modules Terraform puissent output des valeurs que tu pourras ensuite utiliser dans d\u0026rsquo;autres modules. Par exemple, si tu souhaites cr√©er un cloud-run qui se connecte √† une base de donn√©es, il faut que le module de la base de donn√©es output la connection_string de la base de donn√©es, afin que le module cloud-run puisse s\u0026rsquo;y connecter. Concr√®tement, cela peut donner quelque chose comme √ßa pour un cloud-run ayant besoin d\u0026rsquo;exposer une variable d\u0026rsquo;environnement DATABASE_URL :\n# cloud-run/inputs.hcl dependency \u0026#34;cloud_sql\u0026#34; { config_path = \u0026#34;cloud-sql/${basename(get_original_terragrunt_dir())}\u0026#34; mock_outputs = { connection_string = \u0026#34;postgres://user:password@host:port/dbname\u0026#34; } } locals { # On r√©cup√®re la configuration commune d√©finie dans root.hcl common = read_terragrunt_config(find_in_parent_folders(\u0026#34;root.hcl\u0026#34;)).locals config = local.common.config } inputs = { project_id = local.config.project_id region = local.common.region env_name = local.common.env_name secrets = { DATABASE_URL = { value = dependency.cloud_sql.outputs.connection_string } } } Attardons nous un peu sur la partie mock_output. C\u0026rsquo;est une des fonctionnalit√©s Terragrunt qui peuvent se r√©v√©ler int√©ressantes pour le d√©veloppement. En effet, si tu souhaites tester ta configuration sans avoir √† cr√©er l\u0026rsquo;ensemble des ressources, tu peux utiliser mock_output pour simuler les valeurs de sortie d\u0026rsquo;un module. Cela te permet de plan sans obtenir d\u0026rsquo;erreur lorsque le module n\u0026rsquo;est pas encore cr√©√©.\nPour conclure #Concr√®tement, la difficult√© se situe vraiment dans la compr√©hension de la logique de merge de Terragrunt. Pour maintenir une infrastructure DRY, Terragrunt utilise des fonctions et des includes pour fusionner les fichiers de configuration √† l\u0026rsquo;apply. Cela n√©cessite donc (comme souvent lorsqu\u0026rsquo;on automatise) de rendre dynamique la configuration, et de recourir √† des fonctions comme get_parent_terragrunt_dir() ou get_original_terragrunt_dir() afin de variabiliser un maximum.\nTu l\u0026rsquo;as bien compris, la mise en place d\u0026rsquo;une architecture DRY avec Terragrunt reste relativement complexe de part l\u0026rsquo;abstraction qu\u0026rsquo;elle propose. Selon moi, la valeur ajout√©e vaut le coup si :\nTon projet poss√®de de nombreux environnements √† g√©rer (dev, staging, prod, etc..). Tu dois g√©rer un grand nombre d\u0026rsquo;applications/infrastructures identiques, mais dont la configuration diff√®re par environnement (une BDD plus petite en dev\u0026hellip;). Tu souhaites g√©rer des modules Terraform de mani√®re centralis√©e, et versionn√©e, et les appliquer √† l\u0026rsquo;ensemble de tes environnements. Terragrunt devrais √™tre un gros no-go si :\nTon projet est de petite taille, et que tu n\u0026rsquo;as pas besoin de g√©rer plus de deux environnements. Tu n\u0026rsquo;as pas forc√©ment la bande passante et/ou une √©quipe qui te permettra de maintenir tes modules. Tu n\u0026rsquo;est pas 100% √† l\u0026rsquo;aise avec Terraform : pour d√©bugger du Terragrunt il faut √™tre en mesure de r√©ellement comprendre ce qu\u0026rsquo;il applique en arri√®re plan. Cet article d√©cris l\u0026rsquo;organisation et la mani√®re de g√©rer l\u0026rsquo;infrastructure via les commandes ad-hoc Terragrunt (terragrunt plan/apply) afin d\u0026rsquo;en cerner le fonctionnement. Bien entendu, il est possible d\u0026rsquo;utiliser Terragrunt dans un pipeline CI/CD. Une action manag√©e GitHub et d\u0026rsquo;ailleurs propos√©e par Gruntwork, l\u0026rsquo;√©diteur de Terragrunt.\nN\u0026rsquo;h√©sites pas √† me contacter ou de laisser un commentaire si tu souhaites √©changer sur le sujet, j\u0026rsquo;ai l\u0026rsquo;impression que Terragrunt commence √† avoir le vent en poupe, et je serais ravi d\u0026rsquo;en discuter avec toi.\nSources # Terragrunt Documentation Terraform Documentation terragrunt-infrastructure-live-example docs-terraform-guidelines Reduce redundancy in your Terraform code with Terragrunt ","date":"16 avril 2025","permalink":"/blog/informatique/terragrunt-terraform-dry/","section":"Blog","summary":"D√©couverte du wrapper Terragrunt, permettant de g√©rer des configurations Terraform en adoptant une approche DRY (Don\u0026rsquo;t Repeat Yourself).","title":"Terragrunt et d√©couverte de l'IAC en mode DRY"},{"content":" Ce projet √† √©t√© r√©alis√© dans le cadre de ma premi√®re ann√©e de Master, en collaboration avec Matteoz. Je me suis tout particuli√®rement int√©ress√© √† la partie DevOps du projet, √† savoir la mise en place d\u0026rsquo;une pipeline de livraison continue ainsi que la partie infrastructure as code permettant d\u0026rsquo;h√©berger l\u0026rsquo;applicatif. Introduction #Le but de cet article est de r√©sumer la fa√ßon dont j\u0026rsquo;ai appr√©hend√© l\u0026rsquo;int√©gration d\u0026rsquo;un applicatif au sein d\u0026rsquo;une infrastructure dite cloud-native. Ce projet couvrais le d√©veloppement d\u0026rsquo;une API REST, jusqu\u0026rsquo;√† son d√©ploiement de fa√ßon continue sur un environnement AWS impos√©, √† savoir AWS ECS. S\u0026rsquo;agissant d\u0026rsquo;un travail en groupe de deux, la r√©partition de la charge de travail √† √©t√© √©tablie comme ceci :\nMatteoz c\u0026rsquo;est charg√© de la partie d√©veloppement applicative Pour ma part, j\u0026rsquo;ai mis en place une usine logicielle permettant √† mon coll√®gue de d√©ployer l\u0026rsquo;application sur une infrastructure manag√©e par le code. La documentation du projet est aussi industrialis√©e et r√©dig√©e en Markdown puis pouss√©e par Material for MkDocs. L\u0026rsquo;ensemble du code source et la documentation projet est disponible sur le groupe GitLab du projet.\nCet article n\u0026rsquo;as pas pour but de faire doublon avec la doc technique du projet. Il s\u0026rsquo;agit ici de r√©sumer dans les grandes lignes la fa√ßon dont j\u0026rsquo;ai appr√©hend√© la r√©alisation de ce projet Probl√©matique #Comme c\u0026rsquo;est le cas dans une situation pro, le sujet fourni est une forme d\u0026rsquo;expression des besoins ayant pour finalit√© de r√©pondre √† une probl√©matique. Le contexte est donc le suivant :\nUne soci√©t√© appel√©e Solution Libre propose des services internes et externes pour lesquels les probl√©matiques de chiffrement sont essentiels. Pour r√©pondre √† ses besoins en la mati√®re, une API de gestion de certificats doit √™tre d√©velopp√©e. Les fonctionnalit√©s attendues sont indiqu√©es dans le sujet √† savoir :\nUn CRUD permettant la gestion des droits La g√©n√©ration de certificats Leur gestion (CRUD) Leur v√©rification (y compris les certificats externes) C√¥t√© tooling, certaines choses sont impos√©es :\nGolang pour le language de programmation GitLab pour l\u0026rsquo;h√©bergement de code source + CI/CD AWS ECS pour la partie h√©bergement La solution fournie doit √™tre livr√©e sous forme de microservice Un cas DevOps concret #Une dimension essentielle de mon m√©tier consiste √† permettre √† une √©quipe de d√©veloppeurs de d√©ployer leurs applications sans se pr√©occuper des processus de d√©ploiement. Ce projet sert donc d\u0026rsquo;exemple pratique pour illustrer l\u0026rsquo;int√©gration d\u0026rsquo;une application au sein d\u0026rsquo;une infrastructure web.\nCompr√©hension des enjeux #Ma premi√®re r√©flexion, avant m√™me de r√©fl√©chir d\u0026rsquo;un point de vue technique c\u0026rsquo;est de comprendre ce que je dois int√©grer. Ici, il s\u0026rsquo;agit d\u0026rsquo;une API destin√©e √† √™tre utilis√©e en interne. L\u0026rsquo;API ne sera donc pas publique. Le d√©veloppeur travaille sur ce que l\u0026rsquo;on pourrais d√©finir comme un backend, r√©alis√© en Go. Il s\u0026rsquo;appuie sur le framework PocketBase pour la gestion de l\u0026rsquo;authentification. PocketBase embarque une base de donn√©e SQLite int√©gr√©e lui permettant de stocker les users et roles. Pour stocker les certificats g√©n√©r√©s par l\u0026rsquo;application, l\u0026rsquo;API se repose sur une base de donn√©e PostgreSQL. Il souhaiterais proposer un syst√®me de notification permettant d\u0026rsquo;avertir lorsqu\u0026rsquo;un certificat arrive √† expiration. Bien s√ªr, je me dois de proposer un syst√®me permettant au d√©veloppeur de d√©ployer son application de fa√ßon la plus simple possible.\nTraduction des enjeux en faisabilit√© technique # Certaines briques techniques et choix relatifs √† l\u0026rsquo;infrastructure sont impos√©s par le sujet. Cependant, pour garder une logique dans la r√©daction de cet article, je part du principe que j\u0026rsquo;ai moi m√™me arbitr√© ces choix et vais donc argumenter en ce sens. Mon application est une API interne #Cette API ne doit pas √™tre accessible publiquement. Je propose donc :\nD\u0026rsquo;h√©berger cette application dans un subnet priv√©, au sein du VPC de l\u0026rsquo;entreprise. Je met donc en place un bastion permettant de requ√™ter l\u0026rsquo;API lors de la phase de d√©bogage. L\u0026rsquo;acc√®s √† ce bastion sera restreint aux seules personnes autoris√©es. Mon application est d√©velopp√©e en Go #L\u0026rsquo;√©quipe de d√©veloppement me fournit un Dockerfile, me permettant de construire une image qui pourra ensuite √™tre d√©ploy√©e en production. Pour ce faire :\nJe cr√©e un cluster ECS, et pr√©pare un service permettant d\u0026rsquo;h√©berger l\u0026rsquo;image ainsi construite. Pour faciliter un maximum la maintenance, je me base sur une architecture serverless propos√©e par AWS : Fargate. Mon application se base sur un middleware d\u0026rsquo;authentification particulier : PocketBase #Je me documente sur la mani√®re dont PocketBase fonctionne. D\u0026rsquo;un point de vue infrastructure, il faut r√©fl√©chir √† la r√©silience des donn√©es. Premier probl√®me :\nPocketBase ne permet pas d\u0026rsquo;utiliser une base de donn√©e externe, et int√®gre SQLite pour le stockage des users et roles. Plusieurs solutions :\nMonter un volume EFS afin d\u0026rsquo;√™tre en mesure de faire des sauvegardes Apr√®s plusieurs recherches, utiliser SQLite sur un partage r√©seau semble ne pas fonctionner comme voulu.\nPasser par une solution logicielle : LiteStream. LiteStream permet tout simplement de r√©pliquer en temps r√©el la base de donn√©e SQLite vers par exemple, un bucket S3.\nMon application √† besoin d\u0026rsquo;une base de donn√©e PostgreSQL #Je propose d\u0026rsquo;utiliser une solution manag√©e AWS : Aurora\nL\u0026rsquo;√©quipe de d√©veloppeur souhaite mettre en place un syst√®me de notification #Diff√©rents services de communication (Slack, Discord, Teams\u0026hellip;) proposent des int√©grations sous la forme de WebHooks. Dans notre cas, nous avons choisi la solution Discord pour pr√©senter un POC. La feature que j\u0026rsquo;ai propos√©e est disponible dans ce commit.\nL\u0026rsquo;√©quipe de d√©veloppeur doit √™tre autonome dans ses d√©ploiements #Mon infrastructure sera construite as code, et je fournirais des pipelines de d√©ploiement permettant √† l\u0026rsquo;√©quipe de d√©ployer facilement ses versions. Le tout √©tant h√©berg√© sur GitLab, je me baserais sur AutoDevops dans la mesure du possible, afin de ne pas avoir √† maintenir des pipelines complexes. De plus, GitLab propose des outils pratiques permettant par exemple de g√©rer les backends Terraform. Enfin, j\u0026rsquo;ai appris que r√©cemment Terraform change de license. Je choisis d\u0026rsquo;utiliser un fork open-source pour g√©rer mon infrastructure : OpenTofu.\nBien faire attention aux licenses des outils que l\u0026rsquo;on utilise. Bien que la majorit√© des outils DevOps soient open-source, cela peut √™tre amen√© √† changer et poser quelques probl√©matiques lorsqu\u0026rsquo;on propose des services commerciaux bas√©s sur ces outils. Schema d\u0026rsquo;architecture #La meilleure mani√®re de poser des bases concr√®tes quand on parle d\u0026rsquo;architecture informatique, c\u0026rsquo;est de r√©aliser un sch√©ma. Le voici :\nCe schema repr√©sente de fa√ßon graphique l\u0026rsquo;ensemble des points √©voqu√©s ci-dessus L\u0026rsquo;ensemble du code d\u0026rsquo;infrastructure est disponible sur le repo GitLab du projet.\nSp√©cificit√©s li√©es √† l\u0026rsquo;environnement du projet #Nous avons lors de la phase de r√©alisation all√®grement d√©pass√© la limite offerte sur les runners GitLab sur sa version Free. De plus, l\u0026rsquo;environnement AWS fourni par l\u0026rsquo;√©cole comportais certaines restrictions, notamment l\u0026rsquo;impossibilit√© de configurer les r√¥les IAM sur l\u0026rsquo;environnement propos√©. En quoi cela √©tait bloquant :\nLes tasks ECS ne pouvais pas acc√©der aux diff√©rents secrets (login DB, tokens) sans assumer un r√¥le ayant les bonnes policies de configur√©es La solution LiteStream a besoin d\u0026rsquo;un service account afin d\u0026rsquo;√™tre en mesure d\u0026rsquo;√©crire dans le bucket S3. L\u0026rsquo;ensemble des configurations que j\u0026rsquo;ai effectu√©es sont disponibles ici. Pour contourner cela, j\u0026rsquo;ai utilis√© mon compte Cloud Guru pour instancier des sandboxs non restreintes √† la vol√©e. L\u0026rsquo;utilisation de OpenTofu a permis cela de fa√ßon ais√©e, √©tant donn√© que l\u0026rsquo;ensemble de ma configuration est √©crite. En outre, la sandbox ainsi cr√©√©e m\u0026rsquo;as permis de cr√©er une VM EC2 servant en tant que runner, nous permettant de continuer √† d√©ployer via les pipelines CI/CD.\nSi tu souhaites avoir plus de d√©tail sur l\u0026rsquo;ensemble du projet, je t\u0026rsquo;invite √† lire la documentation √©crite pour l\u0026rsquo;occasion.\nConclusion #Encore une vrai mise en pratique propos√©e par notre formateur Thomas Saquet. La conceptualisation, cr√©ation, puis d√©ploiement d\u0026rsquo;un applicatif web de A √† Z est un bon exercice pour r√©ellement comprendre les enjeux auxquels sont confront√©s un DevOps. En effet, il ne s\u0026rsquo;agit pas uniquement de construire une infrastructure, mais d\u0026rsquo;√™tre en mesure de proposer les solutions les plus pertinentes pour mettre en production un applicatif client.\n","date":"10 juin 2024","permalink":"/projets/projet_etude_master/","section":"Projets","summary":"Ce projet √† √©t√© r√©alis√© dans le cadre de ma premi√®re ann√©e de Master, en collaboration avec \u003ca href=\"https://gitlab.com/Toxma\" target=\"_blank\" rel=\"noreferrer\"\u003eMatteoz\u003c/a\u003e.","title":"Int√©gration et livraison continue : d√©ployer une API priv√©e sur le cloud AWS"},{"content":" Cette page rassemble l\u0026rsquo;ensemble de mes projets scolaires et personnels r√©alis√©s en classe ou sur mon temps libre ","date":null,"permalink":"/projets/","section":"Projets","summary":"","title":"Projets"},{"content":" R√©alis√© dans le cadre de ma premi√®re ann√©e de Master, ce projet not√© √† pour but de concevoir une application en CLI permettant de g√©rer/configurer le backend IAM Casdoor.\nL\u0026rsquo;ensemble du code source est disponible en open-source sur GitLab\nIntroduction #Le but de ce projet, outre la d√©couverte de Golang est de r√©fl√©chir √† la mani√®re dont une application en CLI est construite. La seule contrainte impos√©e par le sujet √©tant le fait d\u0026rsquo;utiliser Go, et de choisir parmi 3 backends IAM √† savoir :\nCasdoor Authentik PocketBase Le choix des framework utilis√©s est compl√®tement libre. Pour ma part, j\u0026rsquo;ai choisi Cobra, de part sa maturit√© et sa massive adoption dans divers projets d\u0026rsquo;envergure (comme Docker CLI).\nJ\u0026rsquo;ai d\u0026rsquo;ailleurs d√©couvert que Hugo, le framework que j\u0026rsquo;utilise pour construire mon site web utilise Cobra pour sa CLI! Probl√©matique #G√©n√©ralit√©s #Avant de commencer √† coder, il faut savoir dans quelle direction on souhaite aller. La premi√®re chose √† faire √©tant d\u0026rsquo;installer son environnement de d√©veloppement. Ici, ayant choisi Casdoor il √† fallu embarquer :\nUn container h√©bergeant l\u0026rsquo;application Casdoor Une base de donn√©e MySQL Un fichier permettant d\u0026rsquo;initialiser la base de donn√©e de Casdoor au boot Le but √©tant de permettre au correcteur de facilement tester mon application, l\u0026rsquo;ensemble se doit d\u0026rsquo;√™tre facilement v√©rifiable. Ici, un simple docker compose up -d permet de lancer l\u0026rsquo;ensemble. La documentation du projet se doit d\u0026rsquo;√™tre claire et agr√©able √† lire. Pour ce faire, j\u0026rsquo;ai r√©dig√© un README.md d√©taillant l\u0026rsquo;ensemble des fonctionnalit√©s incluses ainsi qu\u0026rsquo;une documentation permettant d\u0026rsquo;utiliser mon programme.\nMon programme doit en outre √™tre en mesure de :\nCr√©er/Modifier/Supprimer (CRUD) les utilisateurs sur Casdoor Int√©grer une gestion des droits (qui peut faire quoi) Architecture du programme # Dans une interface en ligne de commande, chaque commande est ex√©cut√©e s√©quentiellement, g√©n√©ralement de mani√®re isol√©e. Contrairement √† une application graphique ou une API o√π l\u0026rsquo;√©tat peut √™tre maintenu en permanence en m√©moire vive, un programme CLI doit trouver des moyens alternatifs pour sauvegarder les √©tats entre les ex√©cutions de commandes. Dans le cadre de mon projet, il s\u0026rsquo;agit d\u0026rsquo;√™tre en mesure de persister certaines donn√©es comme un token de login, de fa√ßon s√©curis√©e.\nLe framework Cobra utilis√© dans mon application propose une fa√ßon d\u0026rsquo;organiser son code en suivant une m√©thode bien pr√©cise, d√©taill√©e dans sa documentation.\nR√©alisation #L\u0026rsquo;architecture de mon repo est pr√©sent√©e comme ceci :\n‚îú‚îÄ‚îÄ LICENSE ‚îú‚îÄ‚îÄ Makefile ‚îú‚îÄ‚îÄ README.md ‚îú‚îÄ‚îÄ cmd ‚îÇ¬†‚îú‚îÄ‚îÄ groups.go ‚îÇ¬†‚îú‚îÄ‚îÄ login.go ‚îÇ¬†‚îú‚îÄ‚îÄ oauth.go ‚îÇ¬†‚îú‚îÄ‚îÄ root.go ‚îÇ¬†‚îî‚îÄ‚îÄ users.go ‚îú‚îÄ‚îÄ conf.yml ‚îú‚îÄ‚îÄ config.yaml.example ‚îú‚îÄ‚îÄ dev ‚îÇ¬†‚îî‚îÄ‚îÄ app.conf ‚îú‚îÄ‚îÄ docker-compose.yaml ‚îú‚îÄ‚îÄ go.mod ‚îú‚îÄ‚îÄ go.sum ‚îú‚îÄ‚îÄ handlers ‚îú‚îÄ‚îÄ helpers ‚îÇ¬†‚îú‚îÄ‚îÄ authorize.go ‚îÇ¬†‚îú‚îÄ‚îÄ roles.go ‚îÇ¬†‚îî‚îÄ‚îÄ users.go ‚îú‚îÄ‚îÄ img ‚îÇ¬†‚îú‚îÄ‚îÄ logo.png ‚îÇ¬†‚îú‚îÄ‚îÄ screenshoot.png ‚îÇ¬†‚îú‚îÄ‚îÄ screenshoot_1.png ‚îÇ¬†‚îú‚îÄ‚îÄ screenshoot_2.png ‚îÇ¬†‚îú‚îÄ‚îÄ screenshoot_3.png ‚îÇ¬†‚îî‚îÄ‚îÄ t-rec.gif ‚îú‚îÄ‚îÄ img.png ‚îú‚îÄ‚îÄ init_data.json ‚îú‚îÄ‚îÄ logger ‚îÇ¬†‚îî‚îÄ‚îÄ logger.go ‚îú‚îÄ‚îÄ main.go ‚îú‚îÄ‚îÄ models ‚îÇ¬†‚îî‚îÄ‚îÄ models.go ‚îî‚îÄ‚îÄ utils ‚îú‚îÄ‚îÄ colors.go ‚îú‚îÄ‚îÄ keyring.go ‚îî‚îÄ‚îÄ table.go main.go #A la racine du dossier, on a diff√©rent fichiers dont le main.go permettant d\u0026rsquo;initialiser le programme. J\u0026rsquo;ai s√©par√© mon programme en diff√©rents dossier (modules Go) afin de garder une certaine coh√©rence lors du d√©veloppement.\ncmd #Ce dossier regroupe l\u0026rsquo;ensemble des commandes disponible dans ma CLI. Chaque fichier suit la m√™me logique, et se base sur les m√©thodes d√©taill√©es dans la documentation de Cobra.\nhelpers #Les helpers regroupent des fonctions middlewares, ici permettant de g√©rer l\u0026rsquo;authentification OAuth2 et la gestion des r√¥les utilisateurs.\nutils #Ce dossier regroupes quelques utilitaires que j\u0026rsquo;ai d√©velopp√©, comme la gestion des couleurs dans l\u0026rsquo;output, et le backend permettant de sauvegarder des tokens de fa√ßon s√©curis√© (go-keyring).\nConclusion #Pour une revue plus en d√©tail du projet, je t\u0026rsquo;invites √† consulter le repo disponible ici. Le README.md d√©taille l\u0026rsquo;ensemble des proc√©dures n√©cessaires pour lancer l\u0026rsquo;outil.\nCe projet f√ªt ma r√©elle premi√®re interaction avec Golang. J\u0026rsquo;y ai d√©couvert un langage tr√®s typ√©, assez simple √† appr√©hender. Je pense en approfondir la ma√Ætrise, car la plupart des outils DevOps les plus courants sont cod√©s en Go.\n","date":"6 avril 2024","permalink":"/projets/golang_cli/","section":"Projets","summary":"R√©alis√© dans le cadre de ma premi√®re ann√©e de Master, ce projet not√© √† pour but de concevoir une application en CLI permettant de g√©rer/configurer le backend IAM \u003ca href=\"https://casdoor.org/\" target=\"_blank\" rel=\"noreferrer\"\u003eCasdoor\u003c/a\u003e.","title":"Golang \u0026 CobraCLI : r√©alisation d'une application en ligne de commande"},{"content":" R√©alis√© dans le cadre de mon ann√©e de Bachelor, le Hackaton √† pour but de proposer une solution informatique en une semaine. Un jury juge ensuite la solution la plus convaincante et d√©signe les vainqueurs.\nL\u0026rsquo;ensemble du projet que j\u0026rsquo;ai r√©alis√© est disponible en open-source\nsur GitLab\nEtant encore √©tudiant et loin d\u0026rsquo;√™tre un sp√©cialiste K8S, le projet pr√©sent√© sur cette page comporte forc√©ment de grosses impr√©cisions et d\u0026rsquo;√©normes failles de s√©curit√©. Si par hasard un DevOps confirm√© tombe sur ces lignes, n\u0026rsquo;h√©sites pas √† me contacter via la section commentaire ou via email, j\u0026rsquo;aurais quelques questions √† te poser üòâ Introduction #Lors de ce hackathon, mon √©quipe √† choisi pour sujet Solution Libre. Il s\u0026rsquo;agissait de :\nd√©velopper le frontend d\u0026rsquo;une application √† destination de formateurs et de leurs √©l√®ves d√©velopper l\u0026rsquo;architecture qui permettra in fine d\u0026rsquo;h√©berger l\u0026rsquo;application, son backend et sa base de donn√©es proposer une CI/CD permettant de mettre en place une livraison et une int√©gration continue de l\u0026rsquo;applicatif et son infrastructure Le back-end √©tant fourni par l\u0026rsquo;√©cole, mon travail ici se limitait √† son int√©gration ainsi qu\u0026rsquo;a celle du front-end.\nContexte et travail d\u0026rsquo;√©quipe #L\u0026rsquo;ensemble des √©tudiants de l\u0026rsquo;√©cole sont r√©unis en √©quipe de 10, tout niveaux et sp√©cialit√©s confondues. Toute la difficult√© √©tant de coordonner l\u0026rsquo;ensemble de l\u0026rsquo;√©quipe afin de livrer un produit fonctionnel.\nLimites et difficult√©s #Malheureusement, l\u0026rsquo;√©quipe dont j\u0026rsquo;ai fais partie n\u0026rsquo;as pas s√ª d√©livrer un front-end dans les temps impartis. Cela dit, de mon c√¥t√© j\u0026rsquo;ai pu architecturer l\u0026rsquo;ensemble de l\u0026rsquo;infrastructure ainsi que la pipeline CI/CD et obtenir un POC fonctionnel. Il ne me manquais plus qu\u0026rsquo;un front-end afin d\u0026rsquo;obtenir le r√©sultat demand√©, dommage üò•!\nCependant, j\u0026rsquo;ai pu tester le fonctionnement du back-end sur l\u0026rsquo;architecture ainsi d√©ploy√©e. C\u0026rsquo;est d\u0026rsquo;ailleurs l\u0026rsquo;objet de cet article : pr√©senter ma solution sur la partie DevOps üòé.\nSch√©ma d\u0026rsquo;architecture #J\u0026rsquo;ai r√©alis√© un petit brouillon de l\u0026rsquo;architecture que j\u0026rsquo;ai souhait√© mettre en place sur le cloud Azure :\nOn √† donc:\nUn cluster Kubernetes manag√© sur le cloud Azure (AKS) 3 namepsaces : un pour le front, un pour le back et le dernier pour le monitoring et la gestion des logs Lors de la r√©alisation, j\u0026rsquo;ai regroup√© tout mes pods K8S au sein du m√™me namespace par manque de temps lors du d√©veloppement de la partie Terraform. La partie monitoring est aussi inachev√©e et ne figure pas sur le repo. Cela dit, il n\u0026rsquo;est pas exclu que je m\u0026rsquo;y penche dans le cadre d\u0026rsquo;un article de blog dans un futur proche. En l\u0026rsquo;√©tat, l\u0026rsquo;architecture disponible sur le lien GitLab donn√©e en pr√©ambule permet uniquement de requ√™ter l\u0026rsquo;API du backend. De plus, comme indiqu√© sur le sch√©ma la base de donn√©e utilis√©e est h√©berg√©e dans un pod. J\u0026rsquo;aurais pr√©f√©r√© mettre en place une base de donn√©e manag√©e mais n\u0026rsquo;√©tant pas encore tr√®s √† l\u0026rsquo;aise avec Kubernetes sur Azure, j\u0026rsquo;ai pr√©f√©r√© aller au plus simple. Le but de cet article reste pour moi l\u0026rsquo;occasion de garder une sorte de documentation sur le projet r√©alis√©. A ne pas utiliser en production donc üòâ.\nInfrastructure As Code #Contexte #L\u0026rsquo;enjeu √©tant de provisioner tout cela as code, j\u0026rsquo;ai d√©ploy√© cette architecture avec Terraform. Le repo contenant l\u0026rsquo;infrastructure est construit comme ceci:\n‚îî‚îÄ‚îÄ terraform ‚îú‚îÄ‚îÄ aks.tf ‚îú‚îÄ‚îÄ environment ‚îÇ¬†‚îî‚îÄ‚îÄ dev ‚îÇ¬†‚îî‚îÄ‚îÄ variables.tfvars ‚îú‚îÄ‚îÄ kubernetes.tf ‚îú‚îÄ‚îÄ main.tf ‚îú‚îÄ‚îÄ modules ‚îÇ¬†‚îî‚îÄ‚îÄ kubernetes ‚îÇ¬†‚îú‚îÄ‚îÄ main.tf ‚îÇ¬†‚îú‚îÄ‚îÄ outputs.tf ‚îÇ¬†‚îî‚îÄ‚îÄ variables.tf ‚îú‚îÄ‚îÄ outputs.tf ‚îú‚îÄ‚îÄ rg.tf ‚îú‚îÄ‚îÄ variables.tf ‚îî‚îÄ‚îÄ vpc.tf Cette architecture est d√®s le d√©part con√ßue pour √™tre en mesure de d√©ployer des environments ISO dev/pprd/prod. Cela permet au d√©veloppeur d\u0026rsquo;√™tre en mesure (en th√©orie) de tester son code en amont sur des architectures identiques avant de d√©ployer l\u0026rsquo;applicatif en production.\nBackend et providers #Dans le fichier main.tf, en d√©but de code on retrouve la d√©claration du backend, ainsi que les providers requis:\nterraform { backend \u0026#34;azurerm\u0026#34; { resource_group_name = \u0026#34;backend-terraform-rg\u0026#34; storage_account_name = \u0026#34;backendhackatonsdv\u0026#34; container_name = \u0026#34;terraform-state\u0026#34; key = \u0026#34;terraform.tfstate\u0026#34; } required_providers { azurerm = { source = \u0026#34;hashicorp/azurerm\u0026#34; version = \u0026#34;3.63.0\u0026#34; } kubernetes = { source = \u0026#34;hashicorp/kubernetes\u0026#34; version = \u0026#34;2.21.1\u0026#34; } } } provider \u0026#34;azurerm\u0026#34; { features {} skip_provider_registration = true } provider \u0026#34;kubernetes\u0026#34; { host = module.aks.host client_certificate = base64decode(module.aks.client_certificate) client_key = base64decode(module.aks.client_key) cluster_ca_certificate = base64decode(module.aks.cluster_ca_certificate) } Le backend, permettant de stocker le fichier tfstate consiste en un compte de stockage Azure h√©bergeant ce m√™me fichier. Dans le cas de ce lab, j\u0026rsquo;ai utilis√© un compte de stockage pr√©alablement existant sur mon compte Azure.\nJ\u0026rsquo;utilise les providers azure_rm et kubernetes permettant de respectivement :\nint√©ragir avec mon compte Azure int√©ragir avec le cluster Kubernetes d√©ploy√© J\u0026rsquo;utilise un compte Azure Students fourni par l\u0026rsquo;√©cole pour ce lab. Terraform refusais syst√©matiquement d\u0026rsquo;apply mon infrastructure en raison d\u0026rsquo;erreurs de droits. L\u0026rsquo;option skip_provider_registration = true m\u0026rsquo;as permis de d√©bloquer la situation. Le provider kubernetes n√©cessite une configuration permettant de se connecter au cluster afin d\u0026rsquo;y d√©ployer les ressources. Ici, je fournis les valeurs dynamiquement √† partir du module aks que je decris plus loin dans l\u0026rsquo;article.\nTerraform et modules #Pour une meilleure lisibilit√©, je pr√©f√®re s√©parer chaque ressources d√©ploy√©es en un fichier distinct. Cela √©vite de se retrouver avec un gros fichier de plusieurs centaines de lignes devenant vite illisible. Terraform permet ensuite d\u0026rsquo;organiser son code en modules. Un module est un ensemble de fichiers Terraform stock√©s dans un dossier. Cela permet d\u0026rsquo;√©viter les r√©p√©titions dans le code et la m√©thode de fonctionnement peut √™tre comparable √† une fonction dans un programme informatique. Ici j\u0026rsquo;ai donc :\naks.tf -\u0026gt; Cr√©e un cluster Kubernetes manag√© via le module Azure/aks/azurerm kubernetes.tf -\u0026gt; Int√©ragit avec le cluster Kubernetes. Ce fichier appelle un module que j\u0026rsquo;ai d√©velopp√© et stock√© dans le r√©pertoire modules rg.tf -\u0026gt; Le groupe de ressource Azure contenant l\u0026rsquo;ensemble des instances vpc.tf -\u0026gt; La configuration r√©seau de l\u0026rsquo;infrastructure Pour finir, dans le fichier variables.tf, je d√©clare les variables qui seront utilis√©es pour d√©ployer l\u0026rsquo;infrastructure. Ces variables sont fournies par le fichier variables.tfvars, qui diff√®re en fonction de l\u0026rsquo;environement de production choisi. Ainsi, au plan ou apply il suffira de rajouter le flag -var-file=environment/dev/variables.tfvars afin de d√©finir l\u0026rsquo;environment choisi. Dans ce lab, il s\u0026rsquo;agit de l\u0026rsquo;environment de dev.\nCI/CD #Containerisation #Pour √™tre en mesure de d√©ployer l\u0026rsquo;infrastructure sur Kubernetes, il m\u0026rsquo;a fallu au pr√©alable containairiser le back-end dans une image Docker pr√™te √† √™tre stock√© sur un registre d\u0026rsquo;images (ici, j\u0026rsquo;utilise celui de GitLab). La m√©thode aurais √©t√© similaire pour le front-end. J\u0026rsquo;ai donc √©cris un Dockerfile :\n# Base Golang Image FROM golang:latest # Setup working directory WORKDIR /usr/src/osf-core # Copy source code to COPY . /usr/src/osf-core # Install Git and NodeJS RUN curl -sL https://deb.nodesource.com/setup_16.x | bash - RUN apt-get install -y nodejs npm # Install NPM dependencies RUN npm install -g @marp-team/marp-core \\ \u0026amp;\u0026amp; npm install -g markdown-it-include \\ \u0026amp;\u0026amp; npm install -g markdown-it-container \\ \u0026amp;\u0026amp; npm install -g markdown-it-attrs # Install Go Library \u0026amp; Swagger RUN cd /usr/src/osf-core \u0026amp;\u0026amp; go get golang.org/x/text/transform \\ \u0026amp;\u0026amp; go get golang.org/x/text/unicode/norm \\ \u0026amp;\u0026amp; go install github.com/swaggo/swag/cmd/swag@v1.8.12 # Init Swagger RUN cd /usr/src/osf-core \u0026amp;\u0026amp; swag init --parseDependency --parseInternal # Export ports EXPOSE 8000/tcp EXPOSE 443/tcp EXPOSE 80/tcp # Launch the API CMD [\u0026#34;go\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;/usr/src/osf-core/main.go\u0026#34;] J\u0026rsquo;ai tent√© d\u0026rsquo;utiliser les fichiers packages.json et go.sum/go.mod afin d\u0026rsquo;installer les d√©pendances directement depuis ces fichiers, mais la g√©n√©ration de mon image plantait. De plus, j\u0026rsquo;ai du forcer la version de swagger en 1.8.12 car un probl√®me de compatibilit√© m\u0026rsquo;emp√™chais de g√©n√©rer la documentation Swagger.\nCe Dockerfile est utilis√© dans la CI afin de g√©n√©rer dynamiquement l\u0026rsquo;image destin√© √† √™tre pouss√©e dans le cluster K8S.\nCI applicative #La CI applicative est tr√®s basique pour ce lab mais il y a quelques sp√©cificit√©s. J\u0026rsquo;utilise une image docker in docker, car pour builder l\u0026rsquo;image applicative il est n√©cessaire d\u0026rsquo;executer des commandes docker dans docker (plus d\u0026rsquo;infos ici). Pour fonctionner correctement, le build d\u0026rsquo;une image Docker par le runner n√©cessite d\u0026rsquo;ajouter ces lignes en d√©but de CI :\nimage: docker:20.10.16 services: - docker:20.10.16-dind variables: DOCKER_TLS_CERTDIR: \u0026#34;/certs\u0026#34; Sans cela, docker serais incapable d\u0026rsquo;acc√©der √† Internet √† l\u0026rsquo;int√©rieur du container.\nLa CI consiste en 3 stages :\ntest deploy trigger_deploy_to_terraform 2 variables sont √† renseigner manuellement : ENV et TAG:\nENV: value: \u0026#34;dev\u0026#34; description: \u0026#34;On wich env the image should be deployed\u0026#34; TAG: value: \u0026#34;latest\u0026#34; description: \u0026#34;Version of the image\u0026#34; Ces variables sont utilis√©es par la suite pour d√©finir sur quel environment d√©ployer l\u0026rsquo;image, et permet √† Terraform de r√©cup√©rer le chemin vers l\u0026rsquo;image √† pousser sur le cluster. Le script qui va cr√©er l\u0026rsquo;image est tr√®s simple :\ndeploy: stage: deploy script: - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_TOKEN $DOCKER_REGISTRY_URL - docker build -t registry.gitlab.com/sdv-open-course-factory/ocf-core/${ENV}-backend:${TAG} . - docker push registry.gitlab.com/sdv-open-course-factory/ocf-core/${ENV}-backend:${TAG} Le nom et le chemin de l\u0026rsquo;image sera renseign√© automatiquement en fonction des donn√©es entr√©es par le dev.\nPour finir, le dernier stage d√©clenche la CI situ√©es sur le repo Terraform, en poussant la variable TAG permettant √† Terraform de pousser la bonne image du backend sur le cluster Kubernetes:\nNew job to trigger the other project\u0026#39;s CI trigger_deploy_to_terraform: image: curlimages/curl stage: trigger_deploy_to_terraform script: - curl -X POST --fail -F token=$CI_TRIGGER_TOKEN -F \u0026#34;ref=main\u0026#34; -F \u0026#34;variables[TAG]=$TAG\u0026#34; https://gitlab.com/api/v4/projects/47370418/trigger/pipeline needs: - deploy Je n\u0026rsquo;ai pas encore variabilis√© l\u0026rsquo;environement √† ce niveau. Pour le moment, ma CI est uniquement en mesure de d√©ployer sur dev. Encore une fois, question de priorit√©s niveau timing. Je cherchais surtout √† avoir quelque chose de fonctionnel au plus vite. Ainsi, seul la variable TAG est envoy√©e √† Terraform, permettant de retrouver l\u0026rsquo;image. CI infrastructure #La CI d\u0026rsquo;infrastructure peut soit √™tre d√©clench√©e par le job trigger de la CI applicative, soit manuellement. On retrouve les stages classiques :\nvalidate plan apply destroy J\u0026rsquo;utilise ici l\u0026rsquo;image hashicorp/terraform:latest, m\u0026rsquo;√©vitant d\u0026rsquo;installer Terraform √† chaque d√©ploiement sur le runner.\nAu niveau des variables :\nvariables: TF_ROOT: ${CI_PROJECT_DIR}/terraform/ TF_ENVIRONMENT: \u0026#34;dev\u0026#34; # D√©finissez l\u0026#39;environnement souhait√© ici (par exemple, dev, preprod, prod) TF_DESTROY: description: Destroy Terraform resources value: \u0026#34;false\u0026#34; Comme dit pr√©c√©demment, l\u0026rsquo;environement et cod√© en dur sur dev dans mon lab La variable TF_DESTROY me permet de d√©truire l\u0026rsquo;infrastructure via la CI. Le stage destroy ne s\u0026rsquo;execute seulement ci la valeur est chang√©e pour true:\nterraform_destroy: stage: destroy script: terraform destroy -auto-approve -var-file=environment/${TF_ENVIRONMENT}/variables.tfvars -var=\u0026#34;img_tag=${TAG}\u0026#34; rules: - if: $TF_DESTROY == \u0026#34;true\u0026#34; when: always La partie plan contient un simple script bash qui va tester l\u0026rsquo;existence de la variable TAG r√©cup√©r√©e depuis la CI applicative :\nif [ -n \u0026#34;$TAG\u0026#34; ]; then terraform plan -var-file=environment/${TF_ENVIRONMENT}/variables.tfvars -var \u0026#34;img_tag=${TAG}\u0026#34; else echo \u0026#34;Nothing to plan\u0026#34; fi J\u0026rsquo;utilise le flag -var-file=environment/${TF_ENVIRONMENT}/variables.tfvars afin de d√©terminer dynamiquement sur quel environenment d√©ployer. Puis le flag -var \u0026quot;img_tag=${TAG} pour d√©terminer l\u0026rsquo;image Docker √† utiliser sur le m√™me principe.\nLe flag -var \u0026quot;img_tag=${TAG} permet de d√©finir la variable Terraform contenue dans le variables.tf √† la racine ainsi que dans le module Kubernetes:\nvariable \u0026#34;img_tag\u0026#34; { description = \u0026#34;Image tag\u0026#34; type = string } L\u0026rsquo;adresse permettant de pointer vers l\u0026rsquo;image est ensuite reconstruite comme ceci lors de la cr√©ation du d√©ploiement Kubernetes:\nspec { container { image = \u0026#34;registry.gitlab.com/sdv-open-course-factory/ocf-core/${var.env}-backend:${var.img_tag}\u0026#34; name = \u0026#34;ocf-core-backend\u0026#34; port { container_port = 80 } port { container_port = 443 } port { container_port = 8000 } Conclusion #J\u0026rsquo;ai eu au final √† peu pr√®s 4 jours pour r√©aliser toute cette architecture. C\u0026rsquo;est assez court, mais le POC est fonctionnel et permet d\u0026rsquo;acc√©der √† la doc swagger du backend et de manipuler l\u0026rsquo;API. Dans l\u0026rsquo;id√©e, pour vraiment d√©ployer ce lab en production il faudrais:\nBien s√ªr y int√©grer un front-end Retravailler la CI pour int√©grer l\u0026rsquo;image du front-end Int√©grer toute la partie monitoring et gestion des logs, c\u0026rsquo;est super important Utiliser une BDD manag√©e Azure au lieu d\u0026rsquo;une image PostegrSQL dans le cluster S√©parer chaque services sur des namespaces diff√©rents Niveau s√©curit√©, placer le loadbalancer sur un subnet s√©par√©. Mettre en place un bastion sur un VPC diff√©rent afin d\u0026rsquo;√™tre en mesure de requ√™ter l\u0026rsquo;API K8S via kubectl. Ici, ‚ö†Ô∏è l\u0026rsquo;API est expos√©e au web ‚ö†Ô∏è Je pense r√©-utiliser mon architecture pour tenter de r√©aliser le front-end. J\u0026rsquo;en profiterais pour consolider le tout par rapport √† la liste ci-dessus. Cela fais aussi quelque temps que je suis int√©ress√© par les technologies de dev orient√© front-end (React) et n\u0026rsquo;ayant pas ou tr√®s peu d\u0026rsquo;exp√©rience en JavaScript, ce serais l\u0026rsquo;occasion. Affaire √† suivre donc\u0026hellip;\n","date":"3 juillet 2023","permalink":"/projets/hackaton_sdv/","section":"Projets","summary":"R√©alis√© dans le cadre de mon ann√©e de Bachelor, le Hackaton √† pour but de proposer une solution informatique en une semaine. Un jury juge ensuite la solution la plus convaincante et d√©signe les vainqueurs.","title":"Hackaton Sup De Vinci 2023"},{"content":"","date":null,"permalink":"/categories/aws/","section":"Categories","summary":"","title":"Aws"},{"content":"","date":null,"permalink":"/tags/awscli/","section":"Tags","summary":"","title":"Awscli"},{"content":"","date":null,"permalink":"/tags/cloudformation/","section":"Tags","summary":"","title":"Cloudformation"},{"content":"","date":null,"permalink":"/tags/ec2/","section":"Tags","summary":"","title":"Ec2"},{"content":"","date":null,"permalink":"/tags/gaming/","section":"Tags","summary":"","title":"Gaming"},{"content":"Introduction #Le cloud-gaming se d√©mocratise de plus en plus notamment par le biais d\u0026rsquo;acteurs tel que OVH avec son offre Shadow, ou encore NVDIA avec GeForce Now. Je me suis toujours demand√© par quel proc√©d√© il serais possible de cr√©er mon propre serveur cloud d√©di√© au jeu, et surtout si c\u0026rsquo;√©tait viable. Apr√®s quelques recherches, j\u0026rsquo;ai d√©couvert quelques pistes assez int√©ressantes, notament du c√¥t√© d\u0026rsquo;AWS qui propose des instances de calcul avec GPU plut√¥t abordables : les instances G4.\nAttention √† la facture si tu oublies d\u0026rsquo;√©teindre ou de supprimer ton instance apr√®s avoir d√©roul√© l\u0026rsquo;article! Cet article te permettra de monter ta propre VM GPU, tout en te faisant d√©couvrir aws cli et CloudFormation, l\u0026rsquo;outil d\u0026rsquo;IAC propos√© par AWS.\nLes types d\u0026rsquo;instances G4 #AWS propose deux architectures, l\u0026rsquo;une est bas√©e sur les puces GPU NVIDIA T4 (g4dn), l\u0026rsquo;autre sur des puces AMD Radeon Pro V520 (g4ad). Ci-dessous un tableau comparatif du rapport prix/performances des diff√©rentes instances :\nInstance Type 3DMark Score On-demand Price (us-east-1, USD, 02/23) Price-performance (3DMark points / $) g4dn.xlarge 4300 $0.71 6056 g4dn.2xlarge 4800 $1.12 4286 g4dn.4xlarge 6000 $1.94 3093 g4ad.xlarge 5100 $0.56 9107 g4ad.2xlarge 6600 $0.91 7253 g4ad.4xlarge 7600 $1.60 4750 g5.xlarge 6800 $1.19 5714 g5.2xlarge 10200 $1.58 6456 g5.4xlarge 13000 $2.36 5508 Source : https://github.com/aws-samples/cloud-gaming-on-ec2-instances\nPour cet article, je me base sur une instance AMD g4ad.xlarge, largement suffisante pour mes besoins.\nPr√©requis # Un compte AWS awscli d\u0026rsquo;install√© et de configur√© (voir la doc AWS) Assez de quota sur ton compte AWS pour provisionner des instances GPU G4 (j\u0026rsquo;explique plus bas comment en obtenir) A noter: Il n\u0026rsquo;y a pas de free tier propos√© par AWS sur les instances GPU. Il est essentiel de bien √©teindre ou d√©truire ta VM une fois la session termin√©e afin √©viter d\u0026rsquo;√™tre factur√© pour des heures inutilis√©es\u0026hellip; Infrastructure cible #Mon template CloudFormation permet de g√©n√©rer :\nUn VPC d√©di√© Un subnet public Une instance EC2 g4adn.xlarge avec le syst√®me sur un disque SSD, avec un volume HDD (st1) mont√© pour stocker les jeux Je me suis bas√© sur l\u0026rsquo;ami Microsoft Windows Server 2019 with AMD Radeon Pro Driver propos√©e gratuitement par AWS pour g√©n√©rer mon template. Elle est pr√©configur√©e avec les drivers AMD pr√©install√©s (pratique).\nLes disques st1 sont relativement lents, mais peu cher. J\u0026rsquo;ai choisi cette option ici afin de tester ma config, mais il est conseill√© d\u0026rsquo;utiliser un stockage SSD pour jouer confortablement. D√©ploiement #Quotas de services #Les instances G4 AWS n√©cessitent des quotas pour √™tre provisionn√©es. Par d√©faut, sur ce type d\u0026rsquo;instance, le quota est de 0. Si tu essayes de provisionner une machine G4 en ayant 0 quota, √ßa ne marchera pas. Pour ce faire, connecte toi √† la console AWS et tape service quotas dans la barre de recherche et choisi EC2 :\nDans la barre de recherche sur l\u0026rsquo;√©cran suivant, tape \u0026ldquo;G4\u0026rdquo; et suit les instructions pour augmenter le quota. Le quota correspond au nombres de vCPU allou√©es √† une instance. Pour la g4ad.xlarge, il nous faut 4 vCPU. Changer la valeur du quota par 4, et envoyer.\nIl n\u0026rsquo;est pas possible d\u0026rsquo;obtenir des quotas pour des host dedicated avec un compte AWS personnel qui a peu servi. Apr√®s avoir fait la demande, le service client d\u0026rsquo;AWS la refusera, et te proposera des quotas pour des instances de type spot ou on-demand. J\u0026rsquo;ai demand√© d\u0026rsquo;avoir acc√®s aux instances on-demand suite √† ma premi√®re requ√™te, celles-ci furent disponible le lendemain. D√©ploiement de l\u0026rsquo;EC2 #Si ce n\u0026rsquo;est pas d√©j√† fais, authentifie toi √† awscli. Si tu as besoin d\u0026rsquo;aide, la doc d\u0026rsquo;Amazon est vraiment bien faite.\n√âtant sous MacOS, les commandes suivantes devraient fonctionner sous Linux et MacOS. Si tu es sous Windows, je te conseille de passer via WSL pour b√©n√©ficier d\u0026rsquo;un shell bash. Mon template utilise une KeyPair appel√©e CloudGamingKeyPair permettant de decrypter le mot de passe administrateur de l\u0026rsquo;instance. Pour la cr√©er :\nmkdir ~/.ssh/aws-private-keys \u0026amp;\u0026amp; cd ~/.ssh/aws-private-keys aws ec2 create-key-pair \\ --key-name CloudGamingKeyPair \\ --query \u0026#39;KeyMaterial\u0026#39; \\ --region eu-west-2 \\ --output text \u0026gt; CloudGamingKeyPair.pem Clone mon repo et ce rendre dans le dossier contenant le template :\ngit clone https://github.com/fabienchevalier/ec2-cloudgaming \u0026amp;\u0026amp; cd cloudformation Ouvre le template avec un editeur de texte, et modifie les lignes 60 et 64 en remplacant l\u0026rsquo;adresse par ton adresse IP.\nSecurityGroupIngress: - IpProtocol: tcp FromPort: 8443 #NICE DVC Server ToPort: 8443 CidrIp: 0.0.0.0/0 #Replace that with your IP address (mask should be /32) - IpProtocol: tcp FromPort: 3389 ToPort: 3389 CidrIp: 0.0.0.0/0 #Repl 0.0.0.0/0 autorise n\u0026rsquo;importe quelle adresse sur le port RDP et NICE DCV Server, ce qui n\u0026rsquo;est pas souhaitable.\nTip: tu peux r√©cup√©rer ton adresse ip public via curl ifconfig.me D√©ploie le template CloudFormation :\naws --region eu-west-2 cloudformation deploy \\ --template deploy-cloud-gaming-ec2.cfn.yaml \\ --stack-name CloudGamingStack Il est possible de suivre l\u0026rsquo;avancement de la cr√©ation de la stack sur la console AWS, via la page CloudFormation : Une fois l\u0026rsquo;instance d√©ploy√©e, il faut r√©cup√©rer le mot de passe Administrateur permettant une premi√®re connexion via le protocole RDP.\nOn r√©cup√®re l\u0026rsquo;ID de l\u0026rsquo;instance cr√©e :\naws --region eu-west-2 ec2 describe-instances \\ --filters \u0026#34;Name=tag:Name,Values=CloudGamingInstance\u0026#34; \\ --query \u0026#39;Reservations[].Instances[].[InstanceId]\u0026#39; \\ --output text Copier l\u0026rsquo;ID g√©n√©r√© puis :\naws ec2 get-password-data --instance-id i-1234567890abcdef0 \\ --priv-launch-key ~/.ssh/aws-private-keys/CloudGamingKeyPair.pem Le mot de passe Administrateur se situe dans le champ PasswordData de l\u0026rsquo;output, par exemple :\n{ \u0026#34;InstanceId\u0026#34;: \u0026#34;i-1234567890abcdef0\u0026#34;, \u0026#34;Timestamp\u0026#34;: \u0026#34;2013-08-30T23:18:05.000Z\u0026#34;,z \u0026#34;PasswordData\u0026#34;: \u0026#34;\u0026amp;ViJ652e*u\u0026#34; } On y est presque!\nConfiguration de l\u0026rsquo;instance #Disque dur #Une premi√®re connexion via RDP est n√©cessaire afin de configurer quelques derniers d√©tails. Pour ce faire, lance un client RDP (Microsoft Remote Desktop sous MacOS pour ma part) et connecte toi √† l\u0026rsquo;instance via son IP publique.\nUtilise les informations de login r√©cup√©r√©es auparavant (login Administrator, mot de passe donn√© par la commande ec2 get-password-data) pour te connecter. Cherches disk manager dans la barre de recherche Windows, et formate le disque cr√©√© par le template CloudFormation comme ceci :\nChoisir l\u0026rsquo;option New Simple Volume, et formater l\u0026rsquo;ensemble de l\u0026rsquo;espace disque disponible.\nServeur Nice DCV #Il nous reste √† d√©ployer le serveur Nice DCV permettant de streamer sans latences depuis l\u0026rsquo;instance EC2. Pour ce faire, il faudra se connecter une premi√®re fois en RDP via l\u0026rsquo;adresse IP publique de l\u0026rsquo;EC2 afin d\u0026rsquo;executer ce script PowerShell :\n# Set TLS 1.2 for Invoke-RestMethod [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 # Set the download link to Nice DCV Server (64-bit installer) $downloadUrl = \u0026#34;https://d1uj6qtbmh3dt5.cloudfront.net/nice-dcv-server-x64-Release.msi\u0026#34; # Set the path for our download, which will be in the temp directory $installerFile = \u0026#34;nice-dcv-server-x64-Release.msi\u0026#34; $installerDownloadPath = (Join-Path $env:TEMP $installerFile) # Set the default owner to the current user $installerOwner = [Environment]::UserName # Set Install Command Expression $msiExpression = \u0026#34;msiexec.exe /i $installerDownloadPath AUTOMATIC_SESSION_OWNER=$installerOwner ADDLOCAL=ALL /quiet /norestart /l*v dcv_install_msi.log\u0026#34; # Download the file Invoke-Webrequest $downloadUrl -UseBasicParsing -OutFile $installerDownloadPath # Install Invoke-Expression $msiExpression Pour ce faire, copie/colle ce script dans le notepad de l\u0026rsquo;instance, et enregistre le fichier sur le bureau :\nPuis, clic droit sur l\u0026rsquo;ic√¥ne, puis Run with PowerShell. Attendre une ou deux minutes apr√®s que la fen√™tre se ferme, le temps que le serveur se lance.\nThat\u0026rsquo;s it! Une fois le serveur d√©ploy√©, tu peux fermer ta connexion RDP, et t√©l√©charger le client Nice DCV.\nConnexion √† l\u0026rsquo;instance via Nice DCV #Lance le client, et connecte toi via l\u0026rsquo;adresse IP publique de ton instance, sur le port 8443:\nUne erreur de certificat peut appara√Ætre, clique sur Trust \u0026amp; Connect\nA partir de l√†, libre √† toi d\u0026rsquo;installer tes jeux et de commencer √† jouer !\nJe te conseilles de d√©sactiver le mode de s√©curit√© d\u0026rsquo;IE, navigateur par d√©faut sur Windows Server (h√© oui\u0026hellip;) puis d\u0026rsquo;installer un navigateur r√©cent. Quelques am√©liorations #Par d√©faut, le serveur NICE DCV streame 25 FPS. C\u0026rsquo;est configurable via le registre Windows, via la cl√©e situ√©e ici : HKEY_CURRENT_USER\\Software\\GSettings\\com\\nicesoftware\\dcv. Cr√©er une nouvelle cl√©e display et lui donner pour valeur (type DWORD 32bits) le nombre de FPS souhait√©.\nConclusion #Apr√®s quelques heures d\u0026rsquo;essais, le confort de jeu est plut√¥t bon. Pas trop de latences, m√™me en WiFi. La qualit√© d\u0026rsquo;image est aussi plut√¥t bonne.\nCependant, le co√ªt engendr√© par l\u0026rsquo;utilisation de l\u0026rsquo;EC2 reste trop √©lev√© √† mon sens pour que cela soit viable. En effet, il faut ajouter au prix horaire de l\u0026rsquo;instance :\nLe stockage (assez cher si on choisit de passer par du SSD : +/- 11$/mois) La bande passante : pay√©e au Go, √ßa peut vite s\u0026rsquo;envoler pour du stream 4K@60FPS. Cela dit, cette m√©thode de tarification √† l\u0026rsquo;heure peut convenir √† des joueurs occasionels ne voulant pas s\u0026rsquo;abonner √† un service qu\u0026rsquo;ils utiliserons que tr√®s peu.\nIl est aussi possible d\u0026rsquo;utiliser Parsec pour streamer le contenu du serveur, mais dans sa version gratuite la r√©solution maximale est de 1080p. Si tu remarques des fautes ou quelque chose qui ne fonctionne pas, n\u0026rsquo;h√©sites pas √† le mentionner dans les commentaires !\nA bient√¥t !\n","date":"30 mars 2023","permalink":"/blog/informatique/aws-ec2-cloudgaming-instance/","section":"Blog","summary":"Provisionner facilement son instance gaming en utilisant CloudFormation et NICE DCV Server sur le cloud AWS.","title":"Provisionner sa propre instance de jeu Windows Server dans le cloud AWS via CloudFormation"},{"content":"","date":null,"permalink":"/tags/windows-server-2019/","section":"Tags","summary":"","title":"Windows-Server-2019"},{"content":"","date":null,"permalink":"/tags/appservices/","section":"Tags","summary":"","title":"Appservices"},{"content":"","date":null,"permalink":"/categories/azure/","section":"Categories","summary":"","title":"Azure"},{"content":"","date":null,"permalink":"/tags/azure/","section":"Tags","summary":"","title":"Azure"},{"content":"","date":null,"permalink":"/tags/azuremanagedsql/","section":"Tags","summary":"","title":"Azuremanagedsql"},{"content":"Pr√©requis # Un compte Azure (ici j\u0026rsquo;utilise mon compte Azure Student) Terraform AzureCLI Un compte de stockage Azure, avec un containeur permettant de stocker le terraform.tfstate Dans mon cas, j\u0026rsquo;ai cr√©√© un groupe de ressource d√©di√© √† mon backend via le portail Azure, puis le compte de stockage dans ce groupe :\nCi ce n\u0026rsquo;est pas d√©j√† fait, il faut t\u0026rsquo;authentifier √† Azure via la commande az login et suivre les instructions.\nObjectif #L\u0026rsquo;objectif de cet article est d\u0026rsquo;expliquer la mise en place d\u0026rsquo;une instance GLPI dans le cloud Azure, et de sa base de donn√©e MySQL en utilisant des services manag√©s propos√©s par Microsoft. L\u0026rsquo;int√©gralit√© du code est disponible ce repo . Cet article est bas√© sur le d√©ploiement de GLPI, mais devrais fonctionner avec n\u0026rsquo;importe quelle application web fonctionnant avec une base de donn√©e MySQL.\nInfrastructure cible #Pour d√©ployer notre instance de test, nous allons (dans l\u0026rsquo;ordre) d√©finir :\nUn groupe de ressource Azure qui va contenir l\u0026rsquo;ensemble des ressources Un VPC (Virtual Network sur Azure) 2 subnets : un d√©di√© √† la base de donn√©es, l\u0026rsquo;autre √† l\u0026rsquo;application web. Un serveur manag√© Azure mysql flexible (plan Bs1) Une base de donn√©e manag√©e Azure SQL Un plan App Service Linux (B1) Une App Service Linux Une r√®gle de pare-feu autorisant les instances Azure √† acc√©der √† la base de donn√©e. La base de donn√©e ne sera pas accessible via le web, mais uniquement via notre VPC. En fin de compte, l\u0026rsquo;architecture devrais ressembler √† ceci :\nTerraform #Structure #Notre code Terraform se d√©compose en 3 fichiers :\n‚îú‚îÄ‚îÄ inputs.tf ‚îú‚îÄ‚îÄ main.tf ‚îî‚îÄ‚îÄ outputs.tf inputs.tfd√©finit les variables d\u0026rsquo;entr√©es (adressage, nom des ressources etc). inputs.tf outputs.tfpermet d\u0026rsquo;afficher les donn√©es n√©cessaires pour se connecter √† notre app une fois le d√©ploiement termin√©. outputs.tf main.tf contient l\u0026rsquo;ensemble du code provisionnant l\u0026rsquo;infrastructure. Je vais le d√©tailler ci-dessous. Configuration du backend #Au d√©but du fichier main.tf, je configure le provider Terraform azurerm, en lui indiquant o√π stocker le fichier terraform.statepermettant de garder en m√©moire la configuration de l\u0026rsquo;infrastructure :\nterraform { backend \u0026#34;azurerm\u0026#34; { resource_group_name = \u0026#34;backend-terraform-rg\u0026#34; storage_account_name = \u0026#34;terraformbackend9809\u0026#34; container_name = \u0026#34;terraform\u0026#34; key = \u0026#34;terraform.tfstate\u0026#34; } required_providers { azurerm = { source = \u0026#34;hashicorp/azurerm\u0026#34; version = \u0026#34;~\u0026gt; 3.47.0\u0026#34; } } required_version = \u0026#34;\u0026gt;= 1.4.0\u0026#34; } provider \u0026#34;azurerm\u0026#34; { features {} } Cr√©ation du groupe de ressource #Pour cr√©er des ressources dans Azure, il faut cr√©er un groupe de ressources :\n# Resource Group resource \u0026#34;azurerm_resource_group\u0026#34; \u0026#34;rg\u0026#34; { name = var.resource_group_name location = var.location } A noter: le code reprends les variables d√©finies dans le fichier inputs.tf. Il en va de m√™me pour les exemples suivants. Cr√©ation du VPC et des sous-r√©seaux #L\u0026rsquo;exemple de code ci-dessous cr√©e un VPC, et deux sous r√©seaux. Un pour la base de donn√©e, et un pour l\u0026rsquo;application web :\n# Virtual Network and subnet resource \u0026#34;azurerm_virtual_network\u0026#34; \u0026#34;vnet\u0026#34; { name = var.vnet_name address_space = var.vnet_address_space location = var.location resource_group_name = azurerm_resource_group.rg.name } resource \u0026#34;azurerm_subnet\u0026#34; \u0026#34;mysql_subnet\u0026#34; { name = var.mysql_subnet_name resource_group_name = azurerm_resource_group.rg.name virtual_network_name = azurerm_virtual_network.vnet.name address_prefixes = var.mysql_subnet_address_prefixes service_endpoints = [\u0026#34;Microsoft.Sql\u0026#34;] delegation { name = \u0026#34;vnet-delegation\u0026#34; service_delegation { name = \u0026#34;Microsoft.DBforMySQL/flexibleServers\u0026#34; actions = [ \u0026#34;Microsoft.Network/virtualNetworks/subnets/action\u0026#34; ] } } } resource \u0026#34;azurerm_subnet\u0026#34; \u0026#34;app_service_subnet\u0026#34; { name = var.app_subnet_name resource_group_name = azurerm_resource_group.rg.name virtual_network_name = azurerm_virtual_network.vnet.name address_prefixes = var.app_subnet_address_prefixes delegation { name = \u0026#34;vnet-delegation\u0026#34; service_delegation { name = \u0026#34;Microsoft.Web/serverFarms\u0026#34; actions = [\u0026#34;Microsoft.Network/virtualNetworks/subnets/action\u0026#34;] } } } Les d√©l√©gations configur√©es dans les blocs delegationet service_delegationpermettent de designer ces subnets en tant que cibles pour des ressources PaaS Azure. Serveur de base de donn√©e SQL #J\u0026rsquo;ai choisi de d√©ployer une base de donn√©e de type flexible, en utilisant le plan B_Standard_B1s. C\u0026rsquo;est suffisant pour notre infrastructure, et peu on√©reux. Le tableau des tarifs est disponible ici.\nresource \u0026#34;azurerm_mysql_flexible_server\u0026#34; \u0026#34;mysql\u0026#34; { name = var.mysql_server_name location = azurerm_resource_group.rg.location resource_group_name = azurerm_resource_group.rg.name administrator_login = var.mysql_database_admin_username administrator_password = random_password.mysql_password.result backup_retention_days = 5 sku_name = \u0026#34;B_Standard_B1s\u0026#34; delegated_subnet_id = azurerm_subnet.mysql_subnet.id } Le mot de passe administrateur est g√©n√©r√© al√©atoirement et sera affich√© dans les output apr√®s avoir d√©ploy√© l\u0026rsquo;infrastructure. L\u0026rsquo;option\u0026rsquo; delegated_subnet_id permet d\u0026rsquo;attacher ce serveur au subnet pr√©c√©dement cr√©√©.\nBase de donn√©e SQL ## MySQL Database resource \u0026#34;azurerm_mysql_flexible_database\u0026#34; \u0026#34;mysql\u0026#34; { name = var.mysql_database_name resource_group_name = azurerm_resource_group.rg.name server_name = azurerm_mysql_flexible_server.mysql.name charset = \u0026#34;utf8\u0026#34; collation = \u0026#34;utf8_unicode_ci\u0026#34; } Cet extrait de code cr√©e une base de donn√©e d√©di√©e √† GLPI, sur le serveur MySQL manag√© Azure.\nR√®gles de firewall ## Firewall rule resource \u0026#34;azurerm_mysql_flexible_server_firewall_rule\u0026#34; \u0026#34;fw-mysql\u0026#34; { name = \u0026#34;AllowAzureIPs\u0026#34; resource_group_name = azurerm_resource_group.rg.name server_name = azurerm_mysql_flexible_server.mysql.name start_ip_address = \u0026#34;0.0.0.0\u0026#34; end_ip_address = \u0026#34;0.0.0.0\u0026#34; } Par convention, autoriser les ips 0.0.0.0revient √† autoriser les ressources Azure uniquement d\u0026rsquo;acc√©der √† la base de donn√©e.\nPlan Azure App Service et application App Service #resource \u0026#34;azurerm_service_plan\u0026#34; \u0026#34;glpi-service-plan\u0026#34; { name = var.glpi_app_service_plan_name resource_group_name = azurerm_resource_group.rg.name location = azurerm_resource_group.rg.location os_type = \u0026#34;Linux\u0026#34; sku_name = \u0026#34;B1\u0026#34; } resource \u0026#34;azurerm_linux_web_app\u0026#34; \u0026#34;glpi-app-service\u0026#34; { name = var.glpi_app_service_name resource_group_name = azurerm_resource_group.rg.name location = azurerm_service_plan.glpi-service-plan.location service_plan_id = azurerm_service_plan.glpi-service-plan.id site_config { always_on = false application_stack { docker_image = \u0026#34;diouxx/glpi\u0026#34; docker_image_tag = \u0026#34;latest\u0026#34; } } } #Connect the Azure App to subnet resource \u0026#34;azurerm_app_service_virtual_network_swift_connection\u0026#34; \u0026#34;app\u0026#34; { app_service_id = azurerm_linux_web_app.glpi-app-service.id subnet_id = azurerm_subnet.app_service_subnet.id } Cet extrait de code d√©ploye l\u0026rsquo;application web GLPI au sein d\u0026rsquo;un plan B1. Dans mon exemple, j\u0026rsquo;utilise une image docker GLPI h√©berg√©e sur le docker hub.\nLe plan B1 est le plan App Service le moins cher permettant d\u0026rsquo;attacher un App Service √† un subnet, et ainsi pouvoir communiquer en interne avec la base de donn√©e. D√©ploiement de l\u0026rsquo;infrastructure #Une fois le code r√©dig√© (ou t√©l√©charg√© directement depuis mon repo ), le d√©ploiement s\u0026rsquo;effectue en 3 commandes :\nterraform init terraform plan terraform apply terraform init permet de configurer le backend et r√©cup√©rer le module azurerm. La commande plan permet de passer en revue les changements apport√©s √† l\u0026rsquo;infrastructure, et apply de la d√©ployer :\nSi tout se passe bien, la sortie de la commande apply te donneras le n√©cessaire pour configurer ton app GLPI :\nLe d√©ploiement peut prendre du temps, notamment la base de donn√©e MySQL (+/- 10 minutes dans mon cas). L\u0026rsquo;App Service peut aussi mettre un certain temps avant d\u0026rsquo;√™tre accessible depuis l\u0026rsquo;adresse, le temps que l\u0026rsquo;image docker soit d√©ploy√©e. Derni√®res √©tapes de configuration #Dans l\u0026rsquo;interface d\u0026rsquo;installation de GLPI, saisir les informations donn√©es dans l\u0026rsquo;output terraform. Si tu as utilis√© mon fichier input.tf, l\u0026rsquo;utilisateur SQL sera glpi. La premi√®re tentative de connexion donnera cette erreur :\nPour la corriger, il suffit de se rendre dans les param√®tres de la BDD sur le portail Azure, et de passer le param√®tre require_secure_transportsur OFF:\nIl est normalement d√©sormais possible d\u0026rsquo;installer GLPI sur la base de donn√©e cr√©√©e pour l\u0026rsquo;occasion √† l\u0026rsquo;aide de Terraform:\nV√©rifications #Une fois l\u0026rsquo;application install√©e, on se connecte √† l\u0026rsquo;aide des identifiants par d√©faut (glpi/glpi):\nC\u0026rsquo;est fonctionnel!\nEn raison de la faible puissance de la base de donn√©e manag√©e choisie, l\u0026rsquo;affichage peut √™tre tr√®s long dans l\u0026rsquo;application. Si c\u0026rsquo;est inutilisable, ne pas h√©siter √† augmenter la taille de l\u0026rsquo;instance SQL. Suppression de l\u0026rsquo;infrastructure #Un simple terraform destroyd√©truira l\u0026rsquo;ensemble des ressources cr√©es. A ne pas oublier, le co√ªt mensuel de l\u0026rsquo;App Service peut √™tre √©lev√©.\n","date":"13 mars 2023","permalink":"/blog/informatique/azure-appservices-terraform/","section":"Blog","summary":"En prenant pour example GLPI, je t\u0026rsquo;explique comment d√©ployer une application web compl√®te as code en utilisant App Services","title":"D√©ployer GLPI 10 sur Azure App Services avec une base de donn√©e manag√©e via Terraform"},{"content":"","date":null,"permalink":"/tags/glpi/","section":"Tags","summary":"","title":"Glpi"},{"content":"","date":null,"permalink":"/tags/latex/","section":"Tags","summary":"","title":"Latex"},{"content":"","date":null,"permalink":"/categories/markdown/","section":"Categories","summary":"","title":"Markdown"},{"content":"","date":null,"permalink":"/tags/markdown/","section":"Tags","summary":"","title":"Markdown"},{"content":"","date":null,"permalink":"/tags/pandoc/","section":"Tags","summary":"","title":"Pandoc"},{"content":"","date":null,"permalink":"/tags/pdf/","section":"Tags","summary":"","title":"Pdf"},{"content":"Le language Markdown # Attention Cet article part du principe que vous √™tes d√©j√† √† l\u0026rsquo;aise avec la r√©daction en Markdown. Si ce n\u0026rsquo;est pas le cas, un tutorial interactif assez bien fait est disponible ici Markdown est un language de balisage facile √† utiliser et √† lire. Je m\u0026rsquo;en suis beaucoup servi lors de mes √©tudes pour prendre des notes, car Markdown permet d\u0026rsquo;obtenir un r√©sultat propre tr√®s rapidement avec un simple √©diteur de texte. Diff√©rents logiciels sont compatible avec Markdown, permettant d\u0026rsquo;organiser ses notes et d\u0026rsquo;obtenir un aper√ßu en temps r√©el lors de l\u0026rsquo;√©dition. Personnellement, j\u0026rsquo;utilise Bear sous MacOS:\nInterface principal de Bear, avec le texte format√© en utilisant Markdown Markdown est aussi extr√™mement r√©pandu dans le monde de l\u0026rsquo;informatique, la majorit√© des fichiers README √©tant r√©dig√© en utilisant la syntaxe Markdown.\nLes limites du Markdown #J\u0026rsquo;ai tellement pris l\u0026rsquo;habitude de r√©diger mes documentations et notes en Markdown, que √ßa soit sur VS Code ou sur des applications type Bear, que l\u0026rsquo;utilisation de Word me para√Æt d√©sormais extr√™mement lourde et contre-productive. Le souci, c\u0026rsquo;est que par d√©faut, Markdown n\u0026rsquo;est pas pr√©vu pour g√©n√©rer des documents imprimables. En effet, c\u0026rsquo;est uniquement un language de balisage, con√ßu pour √™tre interpr√©t√© et affich√© √† l\u0026rsquo;√©cran.\nG√©n√©rer un document type \u0026ldquo;M√©moire\u0026rdquo; depuis des fichiers Markdown #Je me suis bas√© sur ce repo pour cr√©er un template (en Fran√ßais) permettant de g√©n√©rer un document adapt√© √† mes rendus d\u0026rsquo;√©cole. Concr√®tement, il s\u0026rsquo;agit ici d\u0026rsquo;utiliser Pandoc associ√© √† un template LaTeX permettant de g√©n√©rer le document. Rassurez-vous, il n\u0026rsquo;est pas n√©cessaire d\u0026rsquo;apprendre LaTeX pour utiliser ce projet, seule certaines commandes suffisent.\n√âtape 1 #R√©cup√©rer sur mon GitHub le template :\ngit clone https://github.com/fabienchevalier/phd_thesis_markdown.git Pandoc n√©cessite LaTeX pour g√©n√©rer des PDF. En fonction de votre OS, il faut donc installer une distribution LaTeX:\nLinux: sudo apt-get install textlive Windows: voir du c√¥t√© de MiKTex MacOS: via homebrew avec brew install --cask mactex Par la suite, mettre √† jour sa distribution LaTeX:\nsudo tlmgr update --self √âtape 2 #Installer Pandoc dans un environnement Python s√©par√©. Personnellement, j\u0026rsquo;utilise miniconda sous MacOS (disponible aussi sur Linux/Windows):\nbrew install miniconda #apt-get install miniconda devrais fonctionner sous Ubuntu/Debian conda create -n phd -y python=3.7 pandoc conda activate phd Les autres d√©pendances peuvent √™tre install√©es automatiquement via le Makefile propos√© :\nmake install √âtape 3 #Par la suite, d√©poser les fichiers md dans le dossier source et executer make pdf pour g√©n√©rer le document au format PDF. Ne pas oublier de modifier le fichier metadata.yml dans le dossier source en fonction des besoins! Un exemple de rendu est disponible ici.\n","date":"7 f√©vrier 2023","permalink":"/blog/informatique/markdown-to-pdf-latex/","section":"Blog","summary":"Comment g√©n√©rer un document type \u0026ldquo;M√©moire\u0026rdquo; au format PDF depuis des fichiers Markdown en utilisant LaTeX et Pandoc","title":"R√©diger son m√©moire universitaire en Markdown"},{"content":" R√©alis√© dans le cadre de mes deux ann√©es de BTS, ce portofolio r√©sume les travaux entrepris lors de ces deux ann√©es d\u0026rsquo;√©tude. Enti√®rement r√©alis√© en Markdown, ce site web est h√©berg√© par GitHub et √† √©t√© construit √† partir du template Jekyll Minimal Mistake.\nhttps://fchevalier.net/bts\n","date":"1 septembre 2022","permalink":"/projets/bts_sio/","section":"Projets","summary":"R√©alis√© dans le cadre de mes deux ann√©es de BTS, ce portofolio r√©sume les travaux entrepris lors de ces deux ann√©es d\u0026rsquo;√©tude.","title":"Portofolio BTS SIO SISR"}]